[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"workshop necessary work prep tasks ensure ready go.currently R RStudio installed, please work Chapter 1.R /RStudio installed, please skip Chapter 1.4 update latest version workshop.technical issues install R RStudio machine (e.g., admin rights), please sign-RStudio Cloud account.done one , work Chapter 2 introduce basic programming terminology install packages need workshop. Depending upon familiarity R, take 1-2 hours.Regardless set-need , join workshop, please ensure completed Workshop Set-Check Chapter 2.9. works, good go.","code":""},{"path":"index.html","id":"workshop-schedule","chapter":"Overview","heading":"0.1 Workshop schedule","text":"One joys teaching R (anything matter) people learn different paces bring different skills prior knowledge. table sets plan workshop, go fast slow need may end covering may go planned. session lasts one hour. Session 1 2 delivered day 1, session 3 4 delivered day 2.materials workshop adapted :Nordmann, E. & DeBruine, L. (2022). Applied Data Skills (1.0). Zenodo. https://doi.org/10.5281/zenodo.6365078Nordmann, E. & DeBruine, L. (2022). Applied Data Skills (1.0). Zenodo. https://doi.org/10.5281/zenodo.6365078Nordmann, E., McAleer, P., Toivo, W., Paterson, H. & DeBruine, L. (accepted). Data visualisation using R, researchers use R. Advances Methods Practices Psychological Science.Nordmann, E., McAleer, P., Toivo, W., Paterson, H. & DeBruine, L. (accepted). Data visualisation using R, researchers use R. Advances Methods Practices Psychological Science.Nordmann, E. & McAleer, P. Fundamentals quantitative analysis (2.0)Nordmann, E. & McAleer, P. Fundamentals quantitative analysis (2.0)","code":""},{"path":"installing-r.html","id":"installing-r","chapter":"1 Prep: Installing R","heading":"1 Prep: Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video . run serious difficulties (example admin rights machine), purposes workshop recommend using RStudio Cloud time trouble-shoot complex installation issues.","code":""},{"path":"installing-r.html","id":"installing-base-r","chapter":"1 Prep: Installing R","heading":"1.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). may also need install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installing-r.html","id":"installing-rstudio","chapter":"1 Prep: Installing R","heading":"1.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installing-r.html","id":"installing-rtools","chapter":"1 Prep: Installing R","heading":"1.3 Installing RTools","text":"using Windows, install R, also install RTools; use \"recommended\" version highlighted near top list. RTools used installing loading packages. can get started without installing RTools, problems installing loading packages, first thing try.RTools require put \"PATH\". instructions can seem bit vague - easiest way open RStudio, run code console:done , restart R clicking Session - Restart R run code console give path RTools installation:","code":"\nwrite('PATH=\"${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}\"', file = \"~/.Renviron\", append = TRUE)\nSys.which(\"make\")##                               make \n## \"C:\\\\rtools40\\\\usr\\\\bin\\\\make.exe\""},{"path":"installing-r.html","id":"rstudio-settings","chapter":"1 Prep: Installing R","heading":"1.4 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure 1.1: RStudio General Appearance settings\nmay also want change settings Code tab. example, Lisa DeBruine prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure 1.2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"1 Prep: Installing R","heading":"1.5 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:","code":"\n# run this in the console\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()"},{"path":"installing-r.html","id":"updating-r","chapter":"1 Prep: Installing R","heading":"1.6 Updating R, RStudio, and packages","text":"time--time, updated versions R, RStudio, packages use (e.g., ggplot) become available. Remember separate, different process come different considerations. recommend updating latest version start new project. definitely recommend updating middle project middle semester bring advice based personal experience pain.","code":""},{"path":"installing-r.html","id":"updating-rstudio","chapter":"1 Prep: Installing R","heading":"1.7 Updating RStudio","text":"RStudio easiest component update. Typically, updates RStudio affect code, instead add new features, like spell-check upgrades RStudio can . usually little downside updating RStudio easy .Click Help - Check updates\nFigure 1.3: Updating RStudio\nupdate available, prompt download can install usual.","code":""},{"path":"installing-r.html","id":"updating-r-1","chapter":"1 Prep: Installing R","heading":"1.8 Updating R","text":"Finally, may also wish update R . key thing aware update R, just download latest version website, lose packages.","code":""},{"path":"installing-r.html","id":"windows","chapter":"1 Prep: Installing R","heading":"1.8.1 Windows","text":"easiest way update R Windows cause huge headache use installr package. use updateR() function, series dialogue boxes appear. fairly self-explanatory full step--step guide available use installr, important bit select \"Yes\" asked like copy packages older version R.","code":"\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Run the update function\ninstallR::updateR()"},{"path":"installing-r.html","id":"mac","chapter":"1 Prep: Installing R","heading":"1.8.2 Mac","text":"Mac, can use updateR package. need install GitHub. asked type system password (use log computer) console pane. relevant, ask want restore packages new major version.","code":"\n# install from github\ndevtools::install_github(\"AndreaCirilloAC/updateR\")\n\n# update your R version, you will need your system password\nupdateR::updateR()"},{"path":"installing-r.html","id":"updating-packages","chapter":"1 Prep: Installing R","heading":"1.9 Updating packages","text":"completely new R installed packages yet, section make great deal sense, just remember can come back future.Package developers occasionally release updates packages. typically add new functions package, fix amend existing functions. aware package updates may cause previous code stop working. tend happen minor updates packages, occasionally major updates, can serious issues developer made fundamental changes code works. reason, recommend updating packages beginning academic year (semester) - assessment deadline just case!update individual package, easiest way use install.packages() function, always installs recent version package.update multiple packages, indeed packages, RStudio provides helpful tools. Click Tools - Check Package Updates. dialogue box appear can select packages wish update. aware select packages, may take time unable use R whilst process completes.\nFigure 1.4: Updating packages RStudio\n","code":"\ninstall.packages(\"tidyverse\")"},{"path":"installing-r.html","id":"package-install-troubleshooting","chapter":"1 Prep: Installing R","heading":"1.10 Troubleshooting","text":"Occasionally, might problem packages seemingly refuse update install. Emily, rlang vctrs cause end trouble. packages likely every explicitly load, required beneath surface R things like knit Markdown files etc.","code":""},{"path":"installing-r.html","id":"non-zero-exit-status","chapter":"1 Prep: Installing R","heading":"1.10.1 Non-zero exit status","text":"try update package get error message says something like Warning install.packages : installation package ‘vctrs’ non-zero exit status perhaps Error loadNamespace(, c(lib.loc, .libPaths()), versionCheck = vI[[]]) :  namespace 'rlang' 0.4.9 loaded, >= 0.4.10 required one solution found manually uninstall package, restart R, install package new, rather trying update existing version. installr package also useful function uninstalling packages.","code":"\n# Load installr\nlibrary(installr)\n\n# Uninstall the problem package\nuninstall.packages(\"package_name\")\n\n# Then restart R using session - restart R\n# Then install the package fresh\n\ninstall.packages(\"package\")"},{"path":"installing-r.html","id":"cannot-open-file","chapter":"1 Prep: Installing R","heading":"1.10.2 Cannot open file","text":"may get following error trying install packages :Error install packages : open file 'C:/.....': Permission deniedThis usually indicates permissions problem writing default library (folder packages kept ). Sometimes means need install R RStudio administrator run administrator.One fix may change library location using following code (check \"C:/Program Files/R\" version instead \"R-3.5.2\"):works can install packages, set library path permanently:Install usethis packageRun usethis::edit_r_profile() console; open blank filePaste file (version ): .libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))Save close fileRestart R changes take effectThe code .Rprofile now run every time start R.","code":"\n# change the library path\n.libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))"},{"path":"intro.html","id":"intro","chapter":"2 Prep: Intro to R and RStudio","heading":"2 Prep: Intro to R and RStudio","text":"","code":""},{"path":"intro.html","id":"ilo-intro","chapter":"2 Prep: Intro to R and RStudio","heading":"2.1 Intended Learning Outcomes","text":"Install R RStudioBe able install add-packagesBe able get help packages functionsBe able create objects writing running code consolePlease note completely new R, expect fully understand everything chapter. Almost concepts explained workshop feel comfortable continued practice. However, first workshop session particular run much smoother familiarity basics.Download RStudio IDE Cheatsheet.","code":""},{"path":"intro.html","id":"intro-r-rstudio","chapter":"2 Prep: Intro to R and RStudio","heading":"2.2 R and RStudio","text":"R programming language write code RStudio Integrated Development Environment (IDE) makes working R easier. Think knowing English using plain text editor like NotePad write book versus using word processor like Microsoft Word. , much harder without things like spell-checking formatting able use advanced features Word developed. similar way, can use R without R Studio recommend . RStudio serves text editor, file manager, spreadsheet viewer, . key thing remember although work using RStudio workshop, actually using two pieces software means time--time, may separate updates.","code":""},{"path":"intro.html","id":"rstudio_ide","chapter":"2 Prep: Intro to R and RStudio","heading":"2.2.1 RStudio","text":"installed R, gave computer ability process R programming language, also installed app called \"R\". never use app. Instead, use RStudio. RStudio arranged four window panes.\nFigure 2.1: RStudio IDE\ndefault, upper left pane source pane, view, write, edit code files view data tables spreadsheet format. first open RStudio, pane display open document load data - worry, get soon.lower left pane console pane, can type commands view output messages. can write code console test . code run can create objects environment, code saved. need write code script source pane save .right panes several different tabs show information code. used tabs upper right pane Environment tab Help tab. environment tab lists information objects defined code. learn Help tab Section 2.6.3.lower right pane, used tabs Files tab directory structure, Plots tab plots made script, Packages tab managing add-packages (see Section 2.5), Viewer tab display reports created scripts. can change location panes tabs shown Preferences > Pane Layout.","code":""},{"path":"intro.html","id":"intro-reproducibility","chapter":"2 Prep: Intro to R and RStudio","heading":"2.2.2 Reproducibility","text":"One main reasons learn R can create reproducible reports. involves writing scripts transform data, create summaries visualisations, embed report way always gives results.things reproducibly, others (future ) can understand check work. can also reuse work easily. example, need create exam board report every semester student grades, reproducible report allows download new data create report within seconds. might take little longer set report first instance reproducible methods, time saves long run invaluable.Section 1.4 shows change two important settings global Options increase reproducibility. settings :Restore .RData workspace startup: CheckedNot CheckedSave workspace .RData exit: AlwaysNeverAsk","code":""},{"path":"intro.html","id":"themes-and-accessiblilty","chapter":"2 Prep: Intro to R and RStudio","heading":"2.2.3 Themes and accessiblilty","text":"can customise R Studio looks make work . Click Tools - Global Options - Appearance. can change default font, font size, general appearance R Studio, including using dark mode. Play around settings see prefer - going spend lot time R, might well look nice!","code":""},{"path":"intro.html","id":"intro-sessions","chapter":"2 Prep: Intro to R and RStudio","heading":"2.3 Sessions","text":"settings configured correctly, open RStudio start writing code, loading packages, creating objects, new session Environment tab completely empty. find code working figure , might worth restarting R session. clear environment detach loaded packages - think like restarting phone. several ways can restart R:Menu: Session > Restart RCmd-Shift-F10 Ctl-Shift-F10type .rs.restartR() consoleTry now. Additionally, now good time create notebook can keep record useful hints tips things try code working. Add \"restart R session\" notebook first item.","code":""},{"path":"intro.html","id":"functions","chapter":"2 Prep: Intro to R and RStudio","heading":"2.4 Functions","text":"install R access range functions including options data wrangling statistical analysis. functions included default installation typically referred base R can think like default apps come pre-loaded phone.function name refers code can reuse. using functions provided packages, can also write functions.type function console pane, run soon hit enter. put function script R Markdown document source pane, run run script, knit R Markdown file, run code chunk. learn workshop.example, function sum() included base R, expect. console, run code:","code":"\nsum(1,2,3)## [1] 6"},{"path":"intro.html","id":"packages","chapter":"2 Prep: Intro to R and RStudio","heading":"2.5 Packages","text":"One great things R, however, user extensible: anyone can create new add-extends functionality. currently thousands packages R users created solve many different kinds problems, just simply fun. example, packages data visualisation, machine learning, interactive dashboards, web scraping, playing games Sudoku.Add-packages distributed base R, downloaded installed archive, way , instance, download install PokemonGo smartphone. main repository packages reside called CRAN, Comprehensive R Archive Network.important distinction installing package loading package.","code":""},{"path":"intro.html","id":"install-package","chapter":"2 Prep: Intro to R and RStudio","heading":"2.5.1 Installing a package","text":"done using install.packages(). like installing app phone: app remain installed remove . instance, want use PokemonGo phone, install App Store Play Store; re-install time want use . launch app, run background close restart phone. Likewise, install package, package available (loaded) every time open R.Install tidyverse package system. package main package use throughout book data wrangling, summaries, visualisation.get message says something like package ‘tidyverse’ successfully unpacked MD5 sums checked, installation successful. get error package installed, check troubleshooting section Appendix 1.10.Never install package inside script. console pane.can also install multiple packages . command install packages using workshop - copy, paste run code. install necessary packagesOnce devtools package, can also install packages repositories CRAN, github. following code installs development version package making waffle plots introdataviz package contains code make advanced plots - copy, paste run code.","code":"\n# type this in the console pane\ninstall.packages(\"tidyverse\")\npackages <- c(\n  \"tidyverse\",  # for everything\n  \"psych\",      # for some useful things\n  \"patchwork\",  # for multi-part plots\n  \"devtools\",   # for installing github packages\n  \"correlation\", # for correlations\n  \"performance\" # for checking model assumptions\n)\n\n# determine which need to be installed\nnew_packages <- packages[!packages %in% installed.packages()]\n\ninstall.packages(new_packages)\ndevtools::install_github(\"hrbrmstr/waffle\")\ndevtools::install_github(\"psyteachr/introdataviz\")"},{"path":"intro.html","id":"loading-a-package","chapter":"2 Prep: Intro to R and RStudio","heading":"2.5.2 Loading a package","text":"done using library() function. like launching app phone: functionality app launched remains close app restart. example, run library(patchwork) within session, functions package referred patchwork made available R session. next time start R, need run library(patchwork) want access package.installing thetidyverse package, can load current R session follows:might get red text load package, normal. usually warning package functions name packages already loaded.can use convention package::function() indicate add-package function resides. instance, see readr::read_csv(), refers function read_csv() readr add-package. package loaded using library(), specify package name function unless conflict (e.g., two packages loaded function name).","code":"\nlibrary(tidyverse)"},{"path":"intro.html","id":"tidyverse","chapter":"2 Prep: Intro to R and RStudio","heading":"2.5.3 Tidyverse","text":"tidyverseis meta-package loads several packages incredibly useful cleaning, processing, summarising, visualising almost type data:ggplot2, data visualisationreadr, data importtibble, tablestidyr, data tidyingdplyr, data manipulationstringr, stringsforcats, factorspurrr, repeating things","code":""},{"path":"intro.html","id":"using-functions","chapter":"2 Prep: Intro to R and RStudio","heading":"2.6 Using functions","text":"","code":""},{"path":"intro.html","id":"arguments","chapter":"2 Prep: Intro to R and RStudio","heading":"2.6.1 Arguments","text":"functions allow/require specify one morearguments. options can set. can look arguments/options function using help documentation. arguments required, optional. Optional arguments often use default (normally specified help documentation) enter value.example, look help documentation function sample() randomly samples items list.help documentation sample() appear bottom right help panel. usage section, see sample() takes following form:arguments section, explanations arguments. x list items want choose , size number items want choose, replace whether item may selected , prob gives probability item chosen. details section notes values entered replace prob use defaults FALSE (item can chosen ) NULL (items equal probability chosen). default value x size, must specified otherwise code run.try example just change required arguments x size ask R choose 5 random letters (letters built-vector 26 lower-case Latin letters).sample() generates random sample. time run code, generate different set random letters (try ). function set.seed() controls random number generator - using functions use randomness (sample()), running set.seed() ensure get result (many cases may want ). get numbers , run set.seed(1242016) console, run sample(x = letters, size = 5) .Now can change default value replace argument produce set letters allowed duplicates.time R still produced 5 random letters, now set letters two instances \"k\". Always remember use help documentation help understand arguments function requires.","code":"\n?sample\nsample(x, size, replace = FALSE, prob = NULL)\nsample(x = letters, size = 5)## [1] \"z\" \"v\" \"y\" \"w\" \"j\"\nset.seed(8675309)\nsample(x = letters, size = 5, replace = TRUE)## [1] \"t\" \"k\" \"j\" \"k\" \"m\""},{"path":"intro.html","id":"argument-names","chapter":"2 Prep: Intro to R and RStudio","heading":"2.6.2 Argument names","text":"examples, written argument names code (.e., x, size, replace), however, strictly necessary. following two lines code produce result (although time run sample() produce slightly different result, random, still work ):Importantly, write argument names, R use default order arguments. sample assume first value enter x. second value size third value replace.write argument names can write arguments whatever order like:first learning R, may find useful write argument names can help remember understand part function . However, skills progress may find quicker omit argument names also see examples code online use argument names, important able understand argument bit code referring (look help documentation check).workshop, always write argument names first time use function. However, subsequent uses may omitted.","code":"\nsample(x = letters, size = 5, replace = TRUE)\nsample(letters, 5, TRUE)\nsample(size = 5, replace = TRUE, x = letters)"},{"path":"intro.html","id":"function-help","chapter":"2 Prep: Intro to R and RStudio","heading":"2.6.3 Function help","text":"load tidyverse automatically loads packages, however, can helpful know package function comes need Google . function base R loaded package, can type ?function_name console access help file. top help give function package name.package loaded, use ?package_name::function_name specify package help() function. sure package function , use shortcut ??function_name.Function help always organised way. example, look help ?stats::rnorm. top, tells name function package curly brackets, short description function, followed longer description. Usage section shows function arguments. arguments default values, shown like function(arg = default).Arguments section lists argument explanation. may Details section even detail functions. Examples section last, shows examples can run console window see function works.first argument mean function? trimna.rmmeanxWhat package read_excel ? readrreadxlbasestats","code":"\n# if the package is loaded\n?ggplot2\nhelp(\"ggplot2\")\n\n# works whether or not the package is loaded\n?ggplot2::ggplot\nhelp(\"ggplot\", package=\"ggplot2\") \n\n# shows a list of potentially matching functions\n??ggplot"},{"path":"intro.html","id":"tab-auto-complete","chapter":"2 Prep: Intro to R and RStudio","heading":"2.6.4 Tab auto-complete","text":"One useful feature R Studio tab auto-complete functions (see Figure 2.2). write name function press tab key, R Studio show arguments function takes along brief description. press enter argument name fill name , just like auto-complete phone. incredibly useful first learning R remember use feature frequently.\nFigure 2.2: Tab auto-complete\n","code":""},{"path":"intro.html","id":"objects","chapter":"2 Prep: Intro to R and RStudio","heading":"2.7 Objects","text":"large part coding involve creating manipulating objects. Objects contain stuff. stuff can numbers, words, result operations analyses. assign content object using <-.Run following code console, change values name age details change christmas holiday date care .see four objects now appear environment pane:name character (text) data. order R recognise character data, must enclosed double quotation marks \" \".age numeric data. order R recognise number, must enclosed quotation marks.today stores result function Sys.Date(). function returns computer system's date. Unlike name age, hard-coded (.e., always return values enter), contents object today change dynamically date. , run function tomorrow, update date tomorrow's date.christmas also date hard-coded specific date. wrapped within .Date() function tells R interpret character string provide date rather text.print contents object, type object's name console press enter. Try printing four objects now.Finally, key concept understand objects can interact can save results interactions new object. Edit run following code create new objects, print contents new object.","code":"\nname <- \"Emily\"\nage <- 36\ntoday <- Sys.Date()\nchristmas <- as.Date(\"2022-12-25\")\ndecade <- age + 10\nfull_name <- paste(name, \"Nordmann\")\nhow_long <- christmas - today"},{"path":"intro.html","id":"help","chapter":"2 Prep: Intro to R and RStudio","heading":"2.8 Getting help","text":"feel like need lot help starting learn. really go away; impossible memorise everything. goal learn enough structure R can look things quickly. introduce specialised jargon glossary; easier google \"convert character numeric R\" \"make numbers quotes actual numbers words\". addition function help described , additional resources use often.","code":""},{"path":"intro.html","id":"package-reference-manuals","chapter":"2 Prep: Intro to R and RStudio","heading":"2.8.1 Package reference manuals","text":"Start help browser entering help.start() console. Click \"Packages\" \"Reference\" see list packages. Scroll readxl package click see list functions available package.","code":""},{"path":"intro.html","id":"googling","chapter":"2 Prep: Intro to R and RStudio","heading":"2.8.2 Googling","text":"function help help, even sure function need, try Googling question. take practice able use right jargon search terms get want. helps put \"R\" \"tidyverse\" search text, name relevant package, like ggplot2.","code":""},{"path":"intro.html","id":"vignettes","chapter":"2 Prep: Intro to R and RStudio","heading":"2.8.3 Vignettes","text":"Many packages, especially tidyverse ones, helpful websites vignettes explaining use functions. vignettes also available inside R. can access package's help page vignette() function.","code":"\n# opens a list of available vignettes\nvignette(package = \"ggplot2\")\n\n# opens a specific vignette in the Help pane\nvignette(\"ggplot2-specs\", package = \"ggplot2\")"},{"path":"intro.html","id":"workshop-prep","chapter":"2 Prep: Intro to R and RStudio","heading":"2.9 Workshop set-up check","text":"Restart R session run code copying pasting console hitting enter. managed install update software packages required, run without issue produce two histograms correlation. produce messages look like errors involving stat_bin, worry, errors explain messages mean workshop.get error package called..., make sure installed packages listed Section 2.5.1.technical issues working machine get code run, please use RStudio Cloud workshop time troubleshoot installation problems.","code":"\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggthemes)\nlibrary(correlation)\n\ndata(starwars)\n\nmass <- ggplot(starwars, aes(x = mass)) +\n  geom_histogram() +\n  theme_economist() +\n  labs(title = \"Star Wars\", \n       subtitle = \"Character Mass (Kg)\",\n       x = NULL, y = NULL)\n\nheight <- ggplot(starwars, aes(x = height)) +\n  geom_histogram() +\n  theme_economist() +\n  labs(subtitle = \"Character Height (cm)\",\n       x = NULL, y = NULL)\n\nmass + height\ncorrelation(data = starwars, select = \"height\", select2 = \"mass\", method = \"pearson\")"},{"path":"intro.html","id":"glossary-intro","chapter":"2 Prep: Intro to R and RStudio","heading":"2.10 Glossary","text":"","code":""},{"path":"intro.html","id":"resources-intro","chapter":"2 Prep: Intro to R and RStudio","heading":"2.11 Further Resources","text":"RStudio IDE CheatsheetRStudio Cloud","code":""},{"path":"session-1-1.html","id":"session-1-1","chapter":"3 Session 1.1","heading":"3 Session 1.1","text":"","code":""},{"path":"session-1-1.html","id":"projects","chapter":"3 Session 1.1","heading":"3.1 Organising a project","text":"write code, first, need get organised. Projects RStudio way group files need one project. projects include scripts, data files, output files like PDF report created script images.folder R look default find save files known working directory. can set working directory manually folder want work menu commands:Session > Set Working Directory > Choose Directory...However, better way organising files using Projects RStudio.","code":""},{"path":"session-1-1.html","id":"project-start","chapter":"3 Session 1.1","heading":"3.1.1 Start a Project","text":"create new project workshop:File > New Project...Name project workshop-datavizSave somewhere sensible computer.RStudio restart open new project directory working directory.\nFigure 3.1: Starting new project.\nClick Files tab lower right pane see contents project directory. see file called workshop-dataviz.Rproj, file contains project information. can double-click open project.Depending settings, may also see directory called .Rproj.user, contains specific user settings. can ignore \"invisible\" files start full stop.","code":""},{"path":"session-1-1.html","id":"error-logs","chapter":"3 Session 1.1","heading":"3.2 Error logs","text":"Coding involves making lot errors. already mentioned Section 2.8. joking! Getting good R really means getting good spotting typos finding extra missing commas. first learning code, can useful keep error log. feel like slowing serve well long-run. give list common errors fix , also start notice patterns errors get.","code":""},{"path":"session-1-1.html","id":"rmarkdown","chapter":"3 Session 1.1","heading":"3.3 R Markdown","text":"workshop use R Markdown. time cover many features R Markdown incredibly powerful format allows create fully reproducible reports text, code, analysis contained within one document. can also use create websites, online books (like one), presentations, Shiny apps. like learn R Markdown, links additional resources Section 3.11.","code":""},{"path":"session-1-1.html","id":"new-document","chapter":"3 Session 1.1","heading":"3.3.1 New document","text":"open new R Markdown document click:File > New File > R MarkdownYou prompted give title; call document Day 1. can also change author name. Keep output format HTML.opened new document sure save clicking File > Save .... name file day_1 (Mac can see file extension, name day_1.Rmd). file automatically saved project folder, .e., working directory, now see file appear file viewer pane.first open new R Markdown document see bunch welcome text looks like :\nFigure 3.2: New R Markdown text\nfollowing steps:Change title \"Intro R session 1\" author nameDelete everything setup chunkSkip line setup chunk type \"## Set-\" (hashes without quotation marks); make sure spaces hashes least one space hashes subtitleSkip line click insert new code menu (green box C plus sign) R","code":""},{"path":"session-1-1.html","id":"code-chunks","chapter":"3 Session 1.1","heading":"3.3.2 Code chunks","text":"created subtitle code chunk. R Markdown, anything written grey code chunk assumed code, anything written white space (code chunks) regarded normal text (actual colours depend theme applied, refer default white grey). makes easy combine text code one document.create new code chunk notice grey box starts ends three back ticks ```. One common mistake accidentally delete back ticks. Remember, code chunks text entry different colours - colour certain parts Markdown look right, check deleted back ticks.code chunk, write code load packages installed prep work.","code":"\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggthemes)"},{"path":"session-1-1.html","id":"running-code","chapter":"3 Session 1.1","heading":"3.3.3 Running code","text":"working R Markdown document, several ways run lines code.First, can highlight code want run click Run -> Run Selected Line(s), however tedious can cause problems highlight exactly code want run.First, can highlight code want run click Run -> Run Selected Line(s), however tedious can cause problems highlight exactly code want run.Alternatively, can press green \"play\" button top-right code chunk run lines code chunk.Alternatively, can press green \"play\" button top-right code chunk run lines code chunk.Even better learn keyboard short cuts R Studio. run single line code, make sure cursor line code want run (can anywhere) press ctrl + enter Cmd + enter Mac. want run code code chunk, press ctrl/cmd + shift + enter. Learn short cuts, make life easier!Even better learn keyboard short cuts R Studio. run single line code, make sure cursor line code want run (can anywhere) press ctrl + enter Cmd + enter Mac. want run code code chunk, press ctrl/cmd + shift + enter. Learn short cuts, make life easier!Run code using method 3. see packages load console.","code":""},{"path":"session-1-1.html","id":"loading-data","chapter":"3 Session 1.1","heading":"3.4 Loading data","text":"Broadly speaking three types data can load working R:Built-data sets come packages install useful reproducible demos. Common ones see Google help documentation mtcars diamonds.Data sets stored online accessed via URL.Data sets stored locally computer.start 1 move 2 3 soon.","code":""},{"path":"session-1-1.html","id":"built-in-data","chapter":"3 Session 1.1","heading":"3.4.1 Built-in data","text":"data() function lists data sets available.Type name data set console see data. example, type ?starwars console see dataset description starwars, data set included dplyr.can also use data() function load dataset global environment.can now use data. Insert new heading (##) named \"first plot\". underneath , create new code chunk, copy, paste, run code. may understand yet, end session.","code":"\n# list datasets built in to base R\ndata()\n\n# lists datasets in a specific package\ndata(package = \"dplyr\")\n?starwars\n# loads starwars into the environment\ndata(\"starwars\")\nggplot(starwars, aes(x = mass)) +\n  geom_histogram(colour = \"black\") +\n  theme_economist() +\n  labs(title = \"Mass of Star Wars characters\",\n       subtitle = \"Original trilogy\")"},{"path":"session-1-1.html","id":"loading-online","chapter":"3 Session 1.1","heading":"3.4.2 Online sources","text":"Now, try loading data stored online. Create code chunk document copy, paste, run code. code loads simulated customer satisfaction data.data stored .csv file going use read_csv() function load .Note url contained within double quotation marks - work without .get error message looks like:Error read_csv(\"https://psyteachr.github.io/ads-v1/data/survey_data.csv\") :\nfind function \"read_csv\"means loaded tidyverse. Check library(tidyverse) setup chunk run setup chunk.data simulated data call centre customer satisfaction survey. first thing need plot data get familiar rows (observations) columns (variables) mean. Sometimes obvious, sometimes requires help data provider. , row represents one call centre.caller_id unique ID calleremployee_id unique ID employee taking callscall_start date time call arrivedwait_time number seconds caller waitcall_time number seconds call lasted employee picked upissue_category whether issue tech, sales, returns, othersatisfaction customer satisfaction rating scale 1 (unsatisfied) 5 (satisfied)Create another heading (##) named \"second plot\", another code chunk , copy, paste, run code .","code":"\nsurvey_data <- read_csv(\"https://psyteachr.github.io/ads-v1/data/survey_data.csv\")\nggplot(survey_data, aes(x = call_time)) +\n  geom_histogram(colour = \"black\", fill = \"wheat\") +\n  theme_excel() +\n  labs(x = \"Time spent on call (seconds)\",\n       title = \"Customer calls\")"},{"path":"session-1-1.html","id":"rmd-knit","chapter":"3 Session 1.1","heading":"3.5 Knitting your file","text":"move focus visualisation, going knit, compile, file document type choosing. knit file click:Knit > Knit HMTLR Markdown create display new HTML document, also automatically save file working directory.can also knit typing following code console. Never put Rmd script , try knit infinite loop.time cover customise knitted output workshop, suffice say can control almost every aspect, whether code displayed hidden, size placement figures.work workshop, encourage use Markdown document take notes code output create complete single record work done. particular, use headings new code chunks separate tasks, () experience error, make note fixed .Ok, get started properly.","code":"\nrmarkdown::render(\"day_1.Rmd\")\n\n# alternatively, you can use this, but may get a warning\nknitr::knit2html(\"day_1.Rmd\")"},{"path":"session-1-1.html","id":"building-plots","chapter":"3 Session 1.1","heading":"3.6 Building plots","text":"multiple approaches data visualisation R; workshop use popular package ggplot2, part larger tidyverse collection packages. grammar graphics (\"gg\" \"ggplot\") standardised way describe components graphic. ggplot2 uses layered grammar graphics, plots built series layers. may helpful think picture multiple elements sit semi-transparently . good analogy old Disney movies artists create background add moveable elements top background via transparencies.Figure 3.3 displays evolution simple scatterplot using layered approach. First, plot space built (layer 1); variables specified (layer 2); type visualisation (known geom) desired variables specified (layer 3) - case geom_point() called visualise individual data points; second geom added include line best fit (layer 4), axis labels edited readability (layer 5), finally, theme applied change overall appearance plot (layer 6).\nFigure 3.3: Evolution layered plot\nImportantly, layer independent independently customisable. example, size, colour position component can adjusted, one , example, remove first geom (data points) visualise line best fit, simply removing layer draws data points (Figure 3.4). use layers makes easy build complex plots step--step, adapt extend plots existing code.\nFigure 3.4: Final plot scatterplot layer removed.\n","code":""},{"path":"session-1-1.html","id":"plot-setup","chapter":"3 Session 1.1","heading":"3.7 Plot setup","text":"","code":""},{"path":"session-1-1.html","id":"plot-setup-data","chapter":"3 Session 1.1","heading":"3.7.1 Data","text":"Every plot starts ggplot() function data table. data loaded typo code, give error message. best check plot step, can figure errors easily.\nFigure 3.5: blank ggplot.\n","code":"\nggplot(data = survey_data)"},{"path":"session-1-1.html","id":"mapping","chapter":"3 Session 1.1","heading":"3.7.2 Mapping","text":"next argument ggplot() mapping. tells plot columns data represented , \"mapped\" , different aspects plot, x-axis, y-axis, line colour, object fill, line style. aspects, \"aesthetics\", listing inside aes() function.Set arguments x y names columns want plotted axes. , want plot wait time x-axis call time y-axis.\nFigure 3.6: blank plot x- y- axes mapped.\nexample , wrote names arguments data mapping, practice, almost everyone omits . Just make sure put data mapping right order.","code":"\n# set up the plot with mapping\nggplot(\n  data = survey_data, \n  mapping = aes(x = wait_time, y = call_time)\n)\nggplot(survey_data,  aes(wait_time, call_time))"},{"path":"session-1-1.html","id":"geoms","chapter":"3 Session 1.1","heading":"3.7.3 Geoms","text":"Now can add plot elements layers. referred geoms functions start geom_. add layers onto base plot created ggplot() plus (+).\nFigure 3.7: Adding scatterplot geom_point().\nSomewhat annoyingly, plus end previous line, start next line. make mistake, run first line code produce base layer get following error message rather adding geom_point().","code":"\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point() # scatterplot\nggplot(survey_data, aes(x = wait_time, y = call_time))\n+ geom_point() # scatterplot## Error:\n## ! Cannot use `+.gg()` with a single argument. Did you accidentally put + on a new line?"},{"path":"session-1-1.html","id":"multiple-geoms","chapter":"3 Session 1.1","heading":"3.7.4 Multiple geoms","text":"Part power ggplot2 can add one geom plot adding extra layers quickly becomes possible make complex informative visualisations. Importantly, layers display order set . code uses geoms produce scatterplot line best fit orders differently.\nFigure 3.8: Points first versus line first.\n","code":"\n# Points first\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point() + # scatterplot\n  geom_smooth(method = lm) # line of best fit\n\n# Line first\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_smooth(method = lm) + # line of best fit\n  geom_point() # scatterplot"},{"path":"session-1-1.html","id":"saving-plots","chapter":"3 Session 1.1","heading":"3.7.5 Saving plots","text":"Just like can save numbers data tables objects, can also save output ggplot(). code produces plots created saves objects named point_first line_first. run code, plots display like done . Instead, see object names appear environment pane.view plots, call objects name. output plot separately.","code":"\npoint_first <- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point() + # scatterplot\n  geom_smooth(method = lm) # line of best fit\n  \nline_first <-\n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_smooth(method = lm) + # line of best fit\n  geom_point() # scatterplot\npoint_first # view first plot\nline_first # view second plot"},{"path":"session-1-1.html","id":"combining-plots","chapter":"3 Session 1.1","heading":"3.7.6 Combining plots","text":"One reasons save plots objects can combine multiple plots using functions patchwork package. code produces plot combining two plots + specifying want plots produced single row nrow argument plot_layout().\nFigure 3.9: Combining plots patchwork.\n","code":"\n# add plots together in 1 row; try changing nrow to 2\npoint_first + line_first + plot_layout(nrow = 1)"},{"path":"session-1-1.html","id":"customising-plots","chapter":"3 Session 1.1","heading":"3.8 Customising plots","text":"","code":""},{"path":"session-1-1.html","id":"format-axes","chapter":"3 Session 1.1","heading":"3.8.1 Format axes","text":"Now need make axes look neater. several functions can use change axis labels, powerful ones scale_ functions. need use scale function matches data plotting axis becomes particularly important know type data working . axes continuous, use scale_x_continuous() scale_y_continuous().name argument changes axis label. breaks argument sets major units needs vector possible values, can extend beyond range data (e.g., wait time goes 350, can specify breaks 600 case wanted reuse code new data different values). seq() function creates sequence numbers one another specified steps.\nFigure 3.10: Formatting plot axes scale_ functions.\nCheck help ?scale_x_continuous see set minor units specify many breaks want instead.","code":"\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) + \n  geom_smooth(method = lm) +\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30))## `geom_smooth()` using formula 'y ~ x'"},{"path":"session-1-1.html","id":"axis-limits","chapter":"3 Session 1.1","heading":"3.8.2 Axis limits","text":"want change minimum maximum values axis, use coord_cartesian() function. Many plots make sense minimum maximum values represent range possible values, even values present data. , wait call times less 0 seconds, set minimum values 0 maximum values first break highest value.\nFigure 3.11: Changing axis limits.\ncan also set limits argument inside scale_ functions, actually removes data falls outside limits, rather cropping plot, can change appearance certain types plots like violin plots density plots.","code":"\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(colour = \"dodgerblue\", \n             alpha = 0.2) + \n  geom_smooth(method = lm) +\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30)) +\n  coord_cartesian(xlim = c(0, 360), \n                  ylim = c(0, 180))## `geom_smooth()` using formula 'y ~ x'"},{"path":"session-1-1.html","id":"themes","chapter":"3 Session 1.1","heading":"3.8.3 Themes","text":"ggplot2 comes several built-themes, theme_minimal() theme_bw(), ggthemes package provides even themes match different software, GoogleDocs Stata, publications, Economist Wall Street Journal. add GoogleDocs theme, change font size 18 base_size argument.also worth highlighting code starting look quite complicated number layers, built slowly (hopefully!) make sense. see examples ggplot2 code online like adapt, build plot layer layer make easier understand layer adds.\nFigure 3.12: Changing theme.\n","code":"\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) + \n  geom_smooth(method = lm, \n              formula = y~x, \n              colour = rgb(0, .5, .8)) +\n  scale_x_continuous(name = \"Wait Time (seconds)\", \n                     breaks = seq(from = 0, to = 600, by = 60)) +\n  scale_y_continuous(name = \"Call time (seconds)\",\n                     breaks = seq(from = 0, to = 600, by = 30)) +\n  coord_cartesian(xlim = c(0, 360), \n                  ylim = c(0, 180)) +\n  ggthemes::theme_gdocs(base_size = 18)"},{"path":"session-1-1.html","id":"appropriate-plots","chapter":"3 Session 1.1","heading":"3.9 Appropriate plots","text":"Now know build plot layers customise appearance, ready learn plot types. Different types data require different types plots, section organised data type.ggplot2 cheat sheet great resource help find plots appropriate data, based many variables plotting type . examples use customer satisfaction data, plot communicates something different.expect memorise plot types methods customising , helpful try code examples , changing values test understanding.","code":""},{"path":"session-1-1.html","id":"counting-categories","chapter":"3 Session 1.1","heading":"3.9.1 Counting categories","text":"","code":""},{"path":"session-1-1.html","id":"bar-plot","chapter":"3 Session 1.1","heading":"3.9.1.1 Bar plot","text":"want count number things per category, can use geom_bar(). need provide x mapping geom_bar() default geom_bar() uses number observations group x value y, need tell put y-axis.","code":"\nggplot(survey_data, aes(x = issue_category)) +\n  geom_bar()"},{"path":"session-1-1.html","id":"one-continuous-variable","chapter":"3 Session 1.1","heading":"3.9.2 One continuous variable","text":"continuous variable, like number seconds callers wait, can use geom_histogram() geom_density() show distribution. Just like geom_bar() required specify x variable.","code":""},{"path":"session-1-1.html","id":"histogram","chapter":"3 Session 1.1","heading":"3.9.2.1 Histogram","text":"histogram splits data \"bins\" along x-axis shows count many observations bin along y-axis.\nFigure 3.13: Histogram wait times.\nalways set binwidth number bins something meaningful data (otherwise get annoying message). might need try options find something looks good conveys meaning plot -- try changing values binwidth bins see works best.default, bars start centered 0, binwidth set 15, first bar include -7.5 7.5 seconds, make much sense. can set boundary = 0 bar represents increments 15 seconds starting 0.Finally, default style grey bars ugly, can change setting fill colour, well using scale_x_continuous() update axis labels.\nFigure 3.14: Histogram custom styles.\n","code":"\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n# adjust width of each bar\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(binwidth = 15)\n\n# adjust number of bars\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(bins = 5)\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(binwidth = 15, boundary = 0)\nggplot(survey_data, aes(x = wait_time)) +\n  geom_histogram(binwidth = 15, \n                 boundary = 0, \n                 fill = \"white\", \n                 color = \"black\") +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60))"},{"path":"session-1-1.html","id":"frequency-plot","chapter":"3 Session 1.1","heading":"3.9.2.2 Frequency plot","text":"Rather plotting bin bar, can connect line across top bin using frequency plot. function geom_freqpoly() works geom_histogram(), except take fill argument just line.","code":"\nggplot(survey_data, aes(x = wait_time)) +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60)) +\n  geom_freqpoly(boundary = 0, binwidth = 15, \n                color = \"black\")"},{"path":"session-1-1.html","id":"density-plot","chapter":"3 Session 1.1","heading":"3.9.2.3 Density plot","text":"distribution smooth, density plot often better way show distribution. density plot need binwidth boundary arguments split data bins, can fill.","code":"\nggplot(survey_data, aes(x = wait_time)) +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60)) +\n  geom_density(fill = \"purple\", color = \"black\")"},{"path":"session-1-1.html","id":"grouped-continuous-variables","chapter":"3 Session 1.1","heading":"3.9.3 Grouped continuous variables","text":"several ways compare continuous data across groups. choose depends point trying make plot.","code":""},{"path":"session-1-1.html","id":"subdividing-distributions","chapter":"3 Session 1.1","heading":"3.9.3.1 Subdividing distributions","text":"previous plots, used fill purely visual reasons, e.g., changed colour histogram bars make look nicer. However, can also use fill represent another variable colours become meaningful.Setting fill aesthetic mapping produce different coloured bars category fill variable, case issue_category.\nFigure 3.15: Histogram categories represented fill.\ndefault, categories positioned stacked top . function geom_area() gives similar effect stat = \"bin\".\nFigure 3.16: Stacked area plot.\n","code":"\nggplot(survey_data, aes(x = wait_time, fill = issue_category)) +\n  geom_histogram(boundary = 0, \n                 binwidth = 15,\n                 color = \"black\")\n# area plot\nggplot(survey_data, mapping = aes(x = wait_time, fill = issue_category)) +\n  geom_area(stat = \"bin\", \n            boundary = 0, \n            binwidth = 15, \n            color = \"black\")"},{"path":"session-1-1.html","id":"comparing-distributions","chapter":"3 Session 1.1","heading":"3.9.3.2 Comparing distributions","text":"want compare one distribution, can set position argument geom_histogram() \"dodge\" put bars group next instead stacking . However, can look confusing several categories. Instead, usegeom_freqpoly() plot line connecting top bin.\nFigure 3.17: Different ways plot distribution continuous variable multiple groups.\n","code":"\n# dodged histogram\nhistogram_dodge <- \n  ggplot(survey_data, aes(x = wait_time, \n                          fill = issue_category,\n                          colour = issue_category))+\n  geom_histogram(boundary = 0, \n                 binwidth = 15, \n                 position = \"dodge\") +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60)) +\n  ggtitle(\"Dodged Histogram\")\n\n# frequency plot\nfreqpoly_plot <- \n  ggplot(survey_data, aes(x = wait_time,\n                          fill = issue_category,\n                          colour = issue_category)) +\n  geom_freqpoly(binwidth = 15, \n                boundary = 0,\n                size = 1) +\n  scale_x_continuous(name = \"Wait time (seconds)\",\n                     breaks = seq(0, 600, 60)) +\n  ggtitle(\"Frequency\")\n\n# put plots together\nhistogram_dodge + freqpoly_plot + \n  plot_layout(nrow = 1, guides = \"collect\") # collects the legends together, try removing this"},{"path":"session-1-1.html","id":"violin-plot","chapter":"3 Session 1.1","heading":"3.9.3.3 Violin plot","text":"Another way compare groups continuous variables violin plot. like density plot, rotated 90 degrees mirrored - fatter violin, larger proportion data points value.\nFigure 3.18: Violin-plot.\n","code":"\nggplot(survey_data, aes(x = issue_category, y = wait_time)) +\n  geom_violin()"},{"path":"session-1-1.html","id":"boxplot","chapter":"3 Session 1.1","heading":"3.9.3.4 Boxplot","text":"Boxplots serve similar purpose violin plots. show shape distribution, rather statistics . middle line represents median; half data line half . box encloses 25th 75th percentiles data, 50% data falls inside box. \"whiskers\" extending box extend 1.5 times height box, although can change coef argument. points show outliers -- individual data points fall outside range.\nFigure 3.19: Basic boxplot.\n","code":"\nggplot(survey_data, aes(x = issue_category, y = wait_time)) +\n geom_boxplot()"},{"path":"session-1-1.html","id":"combo-plots","chapter":"3 Session 1.1","heading":"3.9.3.5 Combo plots","text":"Violin plots frequently layered geoms represent mean median values data. lot code, help understanding ) run layer layer see builds b) change values throughout code\nFigure 3.20: Violin plots combined different methods represent means medians.\n","code":"\n# add fill and colour to the mapping\n\nggplot(survey_data,  aes(x = issue_category, \n                         y = wait_time,\n                         fill = issue_category,\n                         colour = issue_category)) +\n  scale_x_discrete(name = \"Issue Category\") +\n  scale_y_continuous(name = \"Wait Time (seconds)\",\n                     breaks = seq(0, 600, 60)) +\n  coord_cartesian(ylim = c(0, 360)) +\n  guides(fill = \"none\", colour = \"none\") + \n  # add a line at median (50%) score\n  geom_violin(alpha = 0.4, \n              draw_quantiles = 0.5) + \n  # add a boxplot\n  geom_boxplot(width = 0.25, \n               fill = \"white\", \n               alpha = 0.75) + \n  # add a point that represents the mean\n  stat_summary(fun = mean, \n               geom = \"point\", \n               size = 2) + \n  ggtitle(\"ViolinBox\")"},{"path":"session-1-1.html","id":"two-continuous-variables","chapter":"3 Session 1.1","heading":"3.9.4 Two continuous variables","text":"want see two continuous variables related, set one x-axis y-axis. Usually, one variable causes , plot cause x-axis effect y-axis. , want see longer wait times cause calls longer.","code":""},{"path":"session-1-1.html","id":"scatterplot","chapter":"3 Session 1.1","heading":"3.9.4.1 Scatterplot","text":"function create scatterplot called geom_point().\nFigure 3.21: Scatterplot geom_point().\n","code":"\nggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point()"},{"path":"session-1-1.html","id":"trendlines","chapter":"3 Session 1.1","heading":"3.9.4.2 Trendlines","text":"Figure 3.3, emphasised relationship wait time call time trendline created geom_smooth() using argument method = lm (\"lm\" stands \"linear model\" straight line relationship). can also set method = loess visualise non-linear relationship.\nFigure 3.22: Different ways show relationship two continuous variables.\nmuch data extremes x-axis, curve can uncertain. represented wider shaded area, means true relationship might anywhere within area. Add argument se = FALSE geom_smooth() remove \"standard error\" shading.","code":"\nlm_plot <- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = lm) +\n  ggtitle(\"method = lm\")\n\nloess_plot <- \n  ggplot(survey_data, aes(x = wait_time, y = call_time)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = loess) +\n  ggtitle(\"method = loess\")\n\nlm_plot + loess_plot## `geom_smooth()` using formula 'y ~ x'\n## `geom_smooth()` using formula 'y ~ x'"},{"path":"session-1-1.html","id":"ordinal-variables","chapter":"3 Session 1.1","heading":"3.9.5 Ordinal variables","text":"limited range numeric values, ordinal rating scale, sometimes overlapping data makes difficult see going point plot. example, plot shows satisfaction ratings call time ratings 1, 2, 3, 4 5, makes hard see exactly many data points point.section, explore options dealing .\nFigure 3.23: Overlapping data.\n","code":"\nggplot(survey_data, aes(x = call_time, y = satisfaction)) + \n  geom_point()"},{"path":"session-1-1.html","id":"jitter-plot","chapter":"3 Session 1.1","heading":"3.9.5.1 Jitter plot","text":"can use geom_jitter() move points around bit make easier see. can also set alpha transparency. , x-axis continuous, need jitter width, y-axis ordinal categories, height jittered -0.2 +0.2 away true y-value. can help play around values understand jitter .\nFigure 3.24: Jitter plot.\n","code":"\nggplot(survey_data, aes(x = call_time, y = satisfaction)) +\n  geom_jitter(width = 0, height = .2, alpha = 0.5)"},{"path":"session-1-1.html","id":"facets","chapter":"3 Session 1.1","heading":"3.9.5.2 Facets","text":"Alternatively, can use facet_wrap() create separate plot level satisfaction. facet_wrap() uses tilde (~) symbol, can roughly translate \"\", e.g., facet plot satisfaction rating. labeller function controls labels plot. label_both specifies want variable name (satisfaction) value (e.g., 1) printed plot make easier read.\nFigure 3.25: histogram facets.\n, means, plot types can make R. chapter just gave basic overview. resources section end chapter lists many resources, R Graph Gallery especially useful one get inspiration kinds beautiful plots can make R.","code":"\nggplot(survey_data, aes(x = call_time)) +\n  geom_histogram(binwidth = 10, \n                 boundary = 0, \n                 fill = \"dodgerblue\", \n                 color = \"black\") +\n  facet_wrap(~satisfaction, \n             ncol = 1, # try changing this to 2 \n             labeller = label_both) +\n  scale_x_continuous(name = \"Call Time (seconds)\",\n                     breaks = seq(0, 600, 30))"},{"path":"session-1-1.html","id":"glossary-day1","chapter":"3 Session 1.1","heading":"3.10 Glossary","text":"","code":""},{"path":"session-1-1.html","id":"resources-viz","chapter":"3 Session 1.1","heading":"3.11 Further Resources","text":"R Markdown Cheat Sheetggplot2 cheat sheet. R Markdown TutorialR Markdown: Definitive Guide Yihui Xie, J. J. Allaire, & Garrett GrolemundChapter 27: R Markdown R Data ScienceProject Structure Danielle Navarro","code":""},{"path":"session-1-2.html","id":"session-1-2","chapter":"4 Session 1.2","heading":"4 Session 1.2","text":"second session, going whistle-stop tour following paper:Nordmann, E., McAleer, P., Toivo, W., Paterson, H. & DeBruine, L. (accepted). Data visualisation using R, researchers use R. Advances Methods Practices Psychological Science.first half session consolidate skills functions learned Session 1 bit extra data wrangling, however, use simulated experimental data can start thinking might plot types data likely encounter research. second half present advanced plots. Please note extra detail context paper may covered workshop encourage reading full paper already.","code":""},{"path":"session-1-2.html","id":"set-up","chapter":"4 Session 1.2","heading":"4.1 Set-up","text":"Open Workshop project following:Create save new R Markdown document named Session 1.2. get rid default template text line 11 onwards.project folder, create new sub-folder named data.Download simulated dataset Open Science Framework save newly created data folder.Add code set-chunk run code load packages data.","code":"\nlibrary(tidyverse)\nlibrary(patchwork)\ndat <- read_csv(file = \"data/ldt_data.csv\")"},{"path":"session-1-2.html","id":"simulated-dataset","chapter":"4 Session 1.2","heading":"4.2 Simulated dataset","text":"purpose tutorial, use simulated data 2 x 2 mixed-design lexical decision task 100 participants must decide whether presented word real word non-word. 100 rows (1 participant) 7 variables:Participant information:\nid: Participant ID\nage: Age\nParticipant information:id: Participant IDage: Age1 -subject independent variable (IV):\nlanguage: Language group (1 = monolingual, 2 = bilingual)\n1 -subject independent variable (IV):language: Language group (1 = monolingual, 2 = bilingual)4 columns 2 dependent variables (DVs) RT accuracy, crossed within-subject IV condition:\nrt_word: Reaction time (ms) word trials\nrt_nonword: Reaction time (ms) non-word trials\nacc_word: Accuracy word trials\nacc_nonword: Accuracy non-word trials\n4 columns 2 dependent variables (DVs) RT accuracy, crossed within-subject IV condition:rt_word: Reaction time (ms) word trialsrt_nonword: Reaction time (ms) non-word trialsacc_word: Accuracy word trialsacc_nonword: Accuracy non-word trials","code":""},{"path":"session-1-2.html","id":"checking-and-cleaning-your-data","chapter":"4 Session 1.2","heading":"4.3 Checking and cleaning your data","text":"always check importing data resulting table looks like expect. view dataset, click dat environment pane run View(dat) console. environment pane also tells us object dat 100 observations 7 variables, useful quick check ensure one loaded right data. Note 7 variables additional piece information chr num; specifies kind data column. Similar Excel SPSS, R uses information (variable type) specify allowable manipulations data. instance character data id averaged, possible numerical data age.","code":""},{"path":"session-1-2.html","id":"handling-numeric-factors","chapter":"4 Session 1.2","heading":"4.3.1 Handling numeric factors","text":"Another useful check use functions summary() str() (structure) check kind data R thinks column. Run code look output , comparing know simulated dataset:factor language coded 1 2, R categorised column containing numeric information unless correct , cause problems visualisation analysis. code shows recode numeric codes labels.mutate() makes new columns data table, overwrites column;factor() translates language column factor labels \"monolingual\" \"bilingual\". can also use factor() set display order column contains words. Otherwise, display alphabetical order. case replacing numeric data (1 2) language column equivalent English labels monolingual 1 bilingual 2. time change column type factor, R defines categorical data.Make sure always check output code run. running code language full NA values, means run code twice. first time worked transformed values 1 monolingual 2 bilingual. run code dataset, look values 1 2, longer match, return NA. happens, need reload dataset csv file.good way avoid never overwrite data, always store output code new objects (e.g., dat_recoded) new variables (language_recoded). purposes tutorial, overwriting provides useful teachable moment leave .","code":"\nsummary(dat)\nstr(dat)\ndat <- mutate(dat, language = factor(\n  x = language, # column to translate\n  levels = c(1, 2), # values of the original data in preferred order\n  labels = c(\"monolingual\", \"bilingual\") # labels for display\n))"},{"path":"session-1-2.html","id":"basic-plot-recap","chapter":"4 Session 1.2","heading":"4.4 Basic plot recap","text":"code next couple plots quite familiar session 1. run code, try visualise look like reading code.bar chart counts number participants:\nFigure 4.1: Bar chart counts.\nhistogram participant age:\nFigure 4.2: Histogram custom theme.\n","code":"\nggplot(dat, aes(language)) +\n  geom_bar() +\n  scale_x_discrete(name = \"Language group\", \n                   labels = c(\"Monolingual\", \"Bilingual\")) +\n  scale_y_continuous(name = \"Number of participants\",\n                     breaks = seq(from = 0, to = 50, by = 10))\nggplot(dat, aes(age)) +\n  geom_histogram(binwidth = 1, fill = \"wheat\", color = \"black\") +\n  scale_x_continuous(name = \"Participant age (years)\") +\n  theme_minimal()"},{"path":"session-1-2.html","id":"data-formats","chapter":"4 Session 1.2","heading":"4.5 Data formats","text":"visualise experimental reaction time accuracy data using ggplot2, first need reshape data wide format long format. step can cause friction novice users R. Traditionally, psychologists taught data skills using wide-format data. Wide-format data typically one row data participant, separate columns score variable. repeated-measures variables, dependent variable split across different columns. -groups variables, separate column added encode group participant observation belongs.simulated lexical decision data currently wide format (see Table 4.1), participant's aggregated reaction time accuracy level within-subject variable split across multiple columns repeated factor condition (words versus non-words).\nTable 4.1: Data wide format.\nMoving using wide-format long-format datasets can require conceptual shift part researcher one usually comes practice repeated exposure. may helpful make note “row = participant” (wide format) “row = observation” (long format) get used moving formats. example dataset, adhering rules reshaping data produce Table 4.2. Rather different observations dependent variable split across columns, now single column DV reaction time, single column DV accuracy. participant now multiple rows data, one observation (.e., participant many rows levels within-subject IV). Although repetition age language group, row unique looking combination measures.\nTable 4.2: Data correct format visualization.\nbenefits flexibility format hopefully become apparent progress workshop, however, useful rule thumb working data R visualisation anything shares axis probably column. example, simple boxplot showing reaction time condition display variable condition x-axis bars representing word nonword data, rt y-axis. Therefore, data relating condition one column, data relating rt separate single column, rather split like wide-format data.","code":""},{"path":"session-1-2.html","id":"wide-to-long-format","chapter":"4 Session 1.2","heading":"4.5.1 Wide to long format","text":"chosen 2 x 2 design two DVs, anticipate design many researchers familiar may also existing datasets similar structure. However, worth normalising trial--error part process learning apply functions new datasets structures. Data visualisation can useful way scaffold learning data transformations can provide concrete visual check whether done intended data.","code":""},{"path":"session-1-2.html","id":"step-1-pivot_longer","chapter":"4 Session 1.2","heading":"4.5.1.1 Step 1: pivot_longer()","text":"first step use function pivot_longer() transform data long-form. purposefully used complex dataset two DVs tutorial aid researchers applying code datasets. , break steps involved help show code works.first code ignores dataset two DVs, problem fix step 2. pivot functions can easier show tell - may find useful exercise run code compare newly created object long (Table 4.3) original dat Table 4.1 reading .tidyverse functions, first argument specifies dataset use base, case dat. argument name often dropped examples.tidyverse functions, first argument specifies dataset use base, case dat. argument name often dropped examples.cols specifies columns want transform. easiest way visualise think columns new long-form dataset change. refer back Table 4.1, can see id, age, language remain, columns contain measurements DVs change. colon notation first_column:last_column used select variables first column specified last code, cols specifies columns want transform rt_word acc_nonword.cols specifies columns want transform. easiest way visualise think columns new long-form dataset change. refer back Table 4.1, can see id, age, language remain, columns contain measurements DVs change. colon notation first_column:last_column used select variables first column specified last code, cols specifies columns want transform rt_word acc_nonword.names_to specifies name new column created. column contain names selected existing columns.names_to specifies name new column created. column contain names selected existing columns.Finally, values_to names new column contain values selected columns. case call dv.Finally, values_to names new column contain values selected columns. case call dv.point may find helpful go back compare dat long see argument matches output table.\nTable 4.3: Data long format mixed DVs.\n","code":"\nlong <- pivot_longer(data = dat, \n                     cols = rt_word:acc_nonword, \n                     names_to = \"dv_condition\",\n                     values_to = \"dv\")"},{"path":"session-1-2.html","id":"step-2-pivot_longer-adjusted","chapter":"4 Session 1.2","heading":"4.5.1.2 Step 2: pivot_longer() adjusted","text":"problem long-format data-set dv_condition combines two variables - information type DV condition IV. account , include new argument names_sep adjust name_to specify creation two new columns. Note pivoting wide-format dataset dat step 1.names_sep specifies split variable name cases multiple components. taking care name variables consistently meaningfully pays . word left separator (_) always DV type word right always condition within-subject IV, easy automatically split columns.names_sep specifies split variable name cases multiple components. taking care name variables consistently meaningfully pays . word left separator (_) always DV type word right always condition within-subject IV, easy automatically split columns.Note specifying one column name, must combined using c() enclosed quotation marks.Note specifying one column name, must combined using c() enclosed quotation marks.\nTable 4.4: Data long format dv type condition separate columns.\n","code":"\nlong2 <- pivot_longer(data = dat, \n                     cols = rt_word:acc_nonword, \n                     names_sep = \"_\", \n                     names_to = c(\"dv_type\", \"condition\"),\n                     values_to = \"dv\")"},{"path":"session-1-2.html","id":"step-3-pivot_wider","chapter":"4 Session 1.2","heading":"4.5.1.3 Step 3: pivot_wider()","text":"Although now split columns separate variables DV type level condition, two DVs different types data, additional bit wrangling required get data right format plotting.current long-format dataset, column dv contains reaction time accuracy measures. Keeping mind rule thumb anything shares axis probably column, creates problem plot two different units measurement axis. fix need use function pivot_wider(). , encourage point compare long2 dat_long code try map connections reading .first argument dataset wish work , case long2. removed argument name data example.first argument dataset wish work , case long2. removed argument name data example.names_from reverse names_to pivot_longer(). take values variable specified use new column names. case, values rt acc currently dv_type column become new column names.names_from reverse names_to pivot_longer(). take values variable specified use new column names. case, values rt acc currently dv_type column become new column names.values_from reverse values_to pivot_longer(). specifies column contains values fill new columns . case, new columns rt acc filled values dv.values_from reverse values_to pivot_longer(). specifies column contains values fill new columns . case, new columns rt acc filled values dv., can helpful compare dataset code see aligns. final long-form data look like Table 4.2.working dataset one DV, note step 1 process necessary. Also, careful calculate demographic descriptive statistics long-form dataset. process transformation introduced repetition variables, wide-format dataset one row equals one participant used demographic information. Finally, three step process noted broken teaching purposes, reality, one likely single pipeline code, example:Now experimental data right form, can begin create useful visualizations. First, demonstrate code recipes can reused adapted, create histograms reaction time accuracy. code uses template changes dataset (dat_long), bin-widths histograms, x variable display (rt/acc), name x-axis.\nFigure 4.3: Histograms showing distribution reaction time (top) accuracy (bottom)\n","code":"\ndat_long <- pivot_wider(long2, \n                        names_from = \"dv_type\", \n                        values_from = \"dv\")\ndat_long <- pivot_longer(data = dat, \n                         cols = rt_word:acc_nonword, \n                         names_sep = \"_\", \n                         names_to = c(\"dv_type\", \"condition\"),\n                         values_to = \"dv\") %>%\n  pivot_wider(names_from = \"dv_type\", \n              values_from = \"dv\")"},{"path":"session-1-2.html","id":"long-to-wide-format","chapter":"4 Session 1.2","heading":"4.5.2 Long to wide format","text":"Following rule anything shares axis probably column means frequently need data long-form using ggplot2, However, cases wide format necessary. example, may wish visualise relationship reaction time word non-word conditions. requires corresponding word non-word values participant row. easiest way achieve case simply use original wide-format data input:However, may also cases original wide-format version can use pivot_wider() function transform long wide.","code":"\nggplot(dat, aes(x = rt_word, y = rt_nonword)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")## `geom_smooth()` using formula 'y ~ x'\ndat_wide <- dat_long %>%\n  pivot_wider(id_cols = \"id\",\n              names_from = \"condition\", \n              values_from = c(rt,acc))"},{"path":"session-1-2.html","id":"grouped-plots","chapter":"4 Session 1.2","heading":"4.6 Grouped plots","text":"long-form dataset, variable column, much easier specify want create grouped plots.example, can create grouped density plots adding fill = condition:grouped scatterplots adding colour = condition:","code":"\nggplot(dat_long, aes(x = rt, fill = condition)) +\n  geom_density(alpha = 0.75)\nggplot(dat_long, aes(x = rt, y = age, colour = condition)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") ## `geom_smooth()` using formula 'y ~ x'"},{"path":"session-1-2.html","id":"accessible-colour-schemes","chapter":"4 Session 1.2","heading":"4.7 Accessible colour schemes","text":"One drawbacks using ggplot2 visualisation default colour scheme accessible (visually appealing). red green default palette difficult colour-blind people differentiate, also display well greyscale. can specify exact custom colours plots, one easy option use custom colour palette. take arguments default scale sister functions updating axis names labels, display plots contrasting colours can read colour-blind people also print well grey scale. categorical colours, \"Set2\", \"Dark2\" \"Paired\" palettes brewer scale functions colourblind-safe (hard distinhuish greyscale). continuous colours, colour representing magnitude correlation tile plot, viridis scale functions provide number different colourblind greyscale-safe options.","code":"\nggplot(dat_long, aes(x = rt, y = age, colour = condition)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_color_brewer(palette = \"Dark2\",\n                     name = \"Condition\",\n                     labels = c(\"Word\", \"Non-word\"))## `geom_smooth()` using formula 'y ~ x'"},{"path":"session-1-2.html","id":"visualising-summary-statistics","chapter":"4 Session 1.2","heading":"4.8 Visualising summary statistics","text":"Commonly, rather visualising distributions raw data, researchers wish visualise means using bar chart error bars. SPSS Excel, ggplot2 requires calculate summary statistics plot summary. least two ways , first make table summary statistics plot table. second approach calculate statistics within layer plot. approach use .First present code making bar chart. code bar charts common visualisation familiar researchers. However, urge use visualisation provides transparency distribution raw data, violin-boxplots .summarise data means, use stat_summary(). Rather calling geom_* function, call stat_summary() specify want summarise data want present summary figure.fun specifies summary function gives us y-value want plot, case, mean.fun specifies summary function gives us y-value want plot, case, mean.geom specifies shape plot want use display summary. first layer specify bar. geom-type functions shown , part stat_summary() function tied aesthetic mapping first line code. underlying statistics bar chart means must specify IV (x-axis) well DV (y-axis).geom specifies shape plot want use display summary. first layer specify bar. geom-type functions shown , part stat_summary() function tied aesthetic mapping first line code. underlying statistics bar chart means must specify IV (x-axis) well DV (y-axis).add error bars, another layer added second call stat_summary. time, function represents type error bars wish draw, can choose mean_se standard error, mean_cl_normal confidence intervals, mean_sdl standard deviation. width controls width error bars - try changing value see happens.Whilst fun returns single value (y) per condition, fun.data returns y-values want plot plus minimum maximum values, case, mean_se","code":"\nggplot(dat_long, aes(x = condition, y = rt)) +\n  stat_summary(fun = \"mean\", geom = \"bar\")\nggplot(dat_long, aes(x = condition, y = rt)) +\n  stat_summary(fun = \"mean\", geom = \"bar\") +\n  stat_summary(fun.data = \"mean_se\", \n               geom = \"errorbar\", \n               width = .2)"},{"path":"session-1-2.html","id":"grouped-violin-boxplots","chapter":"4 Session 1.2","heading":"4.8.1 Grouped violin-boxplots","text":"previous plots, another variable can mapped fill violin-boxplot can also use stat_summary() add mean errorbars. However, simply adding fill mapping causes different components plot become misaligned different default positions:rectify need adjust argument position misaligned layers. position_dodge() instructs R move (dodge) position plot component specified value; finding value looks best can sometimes take trial error. can also set alpha values make easier distinguish layer plot.","code":"\nggplot(dat_long, aes(x = condition, y= rt, fill = language)) +\n  geom_violin() +\n  geom_boxplot(width = .2, \n               fatten = NULL) +\n  stat_summary(fun = \"mean\",  geom = \"point\") +\n  stat_summary(fun.data = \"mean_se\", \n               geom = \"errorbar\", \n               width = .1) +\n  scale_fill_brewer(palette = \"Dark2\")\nggplot(dat_long, aes(x = condition, y= rt, fill = language)) +\n  geom_violin(alpha = 0.25, position = position_dodge(0.9)) +\n  geom_boxplot(width = .2, \n               fatten = NULL, \n               alpha = 0.75,\n               position = position_dodge(0.9)) +\n  stat_summary(fun = \"mean\", \n               geom = \"point\", \n               position = position_dodge(0.9)) +\n  stat_summary(fun.data = \"mean_se\", \n               geom = \"errorbar\", \n               width = .1,\n               position = position_dodge(0.9)) +\n  scale_fill_brewer(palette = \"Dark2\")"},{"path":"session-1-2.html","id":"combined-interaction-plots","chapter":"4 Session 1.2","heading":"4.8.2 Combined interaction plots","text":"complex interaction plot can produced takes advantage layers visualise overall interaction, change across conditions participant.code complex prior code use universal mapping plot aesthetics. code far, aesthetic mapping (aes) plot specified first line code layers used mapping. However, also possible layer use different mapping -- encourage build plot running line code sequentially see combines.first call ggplot() sets default mappings plot used unless otherwise specified - x, y group variable. Note addition shape, vary shape geom according language variable.geom_point() overrides default mapping setting colour draw data points language group different colour. alpha set low value aid readability.Similarly, geom_line() overrides default grouping variable line drawn connect individual data points participant (group = id) rather language group, also sets colours.Finally, calls stat_summary() remain largely , exception setting colour = \"black\" size = 2 overall means error bars can easily distinguished individual data points. specify individual mapping, use defaults (e.g., lines connected language group). error bars, lines made solid.\nFigure 4.4: Interaction plot -participant data.\n","code":"\nggplot(dat_long, aes(x = condition, y = rt, \n                     group = language, shape = language)) +\n  # adds raw data points in each condition\n  geom_point(aes(colour = language),alpha = .2) +\n  # add lines to connect each participant's data points across conditions\n  geom_line(aes(group = id, colour = language), alpha = .2) +\n  # add data points representing cell means\n  stat_summary(fun = \"mean\", geom = \"point\", size = 2, colour = \"black\") +\n  # add lines connecting cell means by condition\n  stat_summary(fun = \"mean\", geom = \"line\", colour = \"black\") +\n  # add errorbars to cell means\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", \n               width = .2, colour = \"black\") +\n  # change colours and theme\n  scale_color_brewer(palette = \"Dark2\") +\n  theme_minimal()"},{"path":"session-1-2.html","id":"facets-1","chapter":"4 Session 1.2","heading":"4.9 Facets","text":"situations may useful create separate plots level variable using facets. can also help accessibility used instead addition group colours. code adaptation code used produce grouped scatterplot may easier see relationship changes data overlaid.Rather using colour = condition produce different colours level condition, variable instead passed facet_wrap().\nFigure 4.5: Faceted scatterplot\nanother example, can use facet_wrap() alternative grouped violin-boxplot ( variable language passed facet_wrap() rather fill.\nFigure 4.6: Facted violin-boxplot\n","code":"\nggplot(dat_long, aes(x = rt, y = age)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~condition, nrow = 2)## `geom_smooth()` using formula 'y ~ x'\nggplot(dat_long, aes(x = condition, y= rt)) +\n  geom_violin() +\n  geom_boxplot(width = .2, fatten = NULL) +\n  stat_summary(fun = \"mean\", geom = \"point\") +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  facet_wrap(~language) +\n  theme_minimal()"},{"path":"session-1-2.html","id":"axis-labels","chapter":"4 Session 1.2","heading":"4.10 Axis labels","text":"Previously edited main axis labels used scale_* functions. functions useful know allow customise many aspects scale, breaks limits. However, need change main axis name, quicker way using labs(). code adds layer plot changes axis labels histogram saved p1 adds title subtitle. title subtitle conform APA standards (APA formatting additional resources), however, presentations social media can useful.can also use labs() remove axis labels, example, try adjusting code x = NULL.","code":"\nggplot(dat, aes(age)) +\n  geom_histogram(binwidth = 1, fill = \"wheat\", color = \"black\") +\n  labs(x = \"Age\", title = \"Histogram of participant ages\", subtitle = \"Full sample\")"},{"path":"session-1-2.html","id":"redundant-aesthetics","chapter":"4 Session 1.2","heading":"4.11 Redundant aesthetics","text":"far produced plots colours, colours way different levels variable indicated, sometimes preferable indicate levels colour means, facets x-axis categories.code adds fill = condition violin-boxplots. adjust alpha use brewer colour palette customise colours. Specifying fill variable means default, R produces legend variable. However, use colour redundant x-axis labels, can remove legend guides function.","code":"\nggplot(dat_long, aes(x = condition, y= rt, fill = condition)) +\n  geom_violin(alpha = .4) +\n  geom_boxplot(width = .2, fatten = NULL, alpha = .6) +\n  stat_summary(fun = \"mean\", geom = \"point\") +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1) +\n  theme_minimal() +\n  scale_fill_brewer(palette = \"Dark2\") +\n  guides(fill = \"none\")"},{"path":"session-1-2.html","id":"advanced-plots","chapter":"4 Session 1.2","heading":"4.12 Advanced Plots","text":"advanced plots, use custom functions: geom_split_violin() geom_flat_violin(), can access introdataviz package. functions modified Allen et al. (2021).","code":"\n# how to install the introdataviz package to get split and half violin plots\ndevtools::install_github(\"psyteachr/introdataviz\")\n\n# if you get the error \"there is no package called \"devtools\" run:\n# install.packages(\"devtools\") "},{"path":"session-1-2.html","id":"split-violin-plots","chapter":"4 Session 1.2","heading":"4.12.1 Split-violin plots","text":"Split-violin plots remove redundancy mirrored violin plots make easier compare distributions multiple conditions.","code":"\nggplot(dat_long, aes(x = condition, y = rt, fill = language)) +\n  introdataviz::geom_split_violin(alpha = .4) +\n  geom_boxplot(width = .2, alpha = .6) +\n  stat_summary(fun.data = \"mean_se\", geom = \"pointrange\", \n               position = position_dodge(.175)) +\n  scale_x_discrete(name = \"Condition\", labels = c(\"Non-word\", \"Word\")) +\n  scale_y_continuous(name = \"Reaction time (ms)\",\n                     breaks = seq(200, 800, 100), \n                     limits = c(200, 800)) +\n  scale_fill_brewer(palette = \"Dark2\", name = \"Language group\") +\n  theme_minimal() +\n  guides(fill = \"none\")"},{"path":"session-1-2.html","id":"raincloud-plots","chapter":"4 Session 1.2","heading":"4.13 Raincloud plots","text":"Raincloud plots combine density plot, boxplot, raw data points, desired summary statistics complete visualisation data. called density plot plus raw data reminiscent rain cloud. point line centre cloud represents mean 95% CI. rain represents individual data points.","code":"\nrain_height <- .1\n\nggplot(dat_long, aes(x = \"\", y = rt, fill = language)) +\n  # clouds\n  introdataviz::geom_flat_violin(alpha = 0.4,\n    position = position_nudge(x = rain_height+.05)) +\n  # rain\n  geom_point(aes(colour = language), size = 2, alpha = .5, \n              position = position_jitter(width = rain_height, height = 0)) +\n  # boxplots\n  geom_boxplot(width = rain_height, alpha = 0.4, \n               position = position_nudge(x = -rain_height*2)) +\n  # mean and SE point in the cloud\n  stat_summary(fun.data = mean_cl_normal, mapping = aes(color = language), \n               position = position_nudge(x = rain_height * 3)) +\n  # adjust layout\n  scale_x_discrete(name = \"\", expand = c(rain_height*3, 0, 0, 0.7)) +\n  scale_y_continuous(name = \"Reaction time (ms)\",\n                     breaks = seq(200, 800, 100), \n                     limits = c(200, 800)) +\n  coord_flip() +\n  facet_wrap(~factor(condition, \n                     levels = c(\"word\", \"nonword\"), \n                     labels = c(\"Word\", \"Non-Word\")), \n             nrow = 2) +\n  # custom colours and theme\n  scale_fill_brewer(palette = \"Dark2\", name = \"Language group\") +\n  scale_colour_brewer(palette = \"Dark2\") +\n  theme_minimal() +\n  theme(panel.grid.major.y = element_blank(),\n        legend.position = c(0.8, 0.8),\n        legend.background = element_rect(fill = \"white\", color = \"white\")) +\n  guides(fill = \"none\")"},{"path":"session-1-2.html","id":"glossary-1-2","chapter":"4 Session 1.2","heading":"4.14 Glossary","text":"","code":""},{"path":"session-1-2.html","id":"resources-1-2","chapter":"4 Session 1.2","heading":"4.15 Further Resources","text":"Applied Data Skils: Data visualisation (PsyTeachR team)Applied Data Skils: Customising visualisations (PsyTeachR team)ggplot2 cheat sheetData visualisation using R, researchers use RChapter 3: Data Visualisation R Data Scienceggplot2 FAQsggplot2 documentationHack Data Beautiful workshop University Glasgow postgraduate studentsChapter 28: Graphics communication R Data Sciencegganimate: package making animated plotsThe R Graph Gallery (really useful)Look Data Data Vizualization Social ScienceGraphs Cookbook RTop 50 ggplot2 VisualizationsR Graphics Cookbook Winston Changggplot extensionsplotly creating interactive graphsDrawing Beautiful Maps Programmatically","code":""},{"path":"session-2-1.html","id":"session-2-1","chapter":"5 Session 2.1","heading":"5 Session 2.1","text":"","code":""},{"path":"session-2-1.html","id":"set-up-1","chapter":"5 Session 2.1","heading":"5.1 Set-up","text":"Open Workshop project following:Create save new R Markdown document named Session 2.1. get rid default template text line 11 onwards.Add code set-chunk run code load packages data.","code":"\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(psych)\ndat <- read_csv(file = \"data/ldt_data.csv\") %>%\n  mutate(language = factor(\n  x = language, # column to translate\n  levels = c(1, 2), # values of the original data in preferred order\n  labels = c(\"monolingual\", \"bilingual\") # labels for display\n))\n\ndat_long <- pivot_longer(data = dat, \n                         cols = rt_word:acc_nonword, \n                         names_sep = \"_\", \n                         names_to = c(\"dv_type\", \"condition\"),\n                         values_to = \"dv\") %>%\n  pivot_wider(names_from = \"dv_type\", \n              values_from = \"dv\")"},{"path":"session-2-1.html","id":"counting-groups","chapter":"5 Session 2.1","heading":"5.2 Counting groups","text":"can calculate plot basic descriptive information demographics sample using oroginal wide-form dataset without additional wrangling (.e., data processing). code uses %>% operator can read :Start dataset dat ;Start dataset dat ;Group variable language ;Group variable language ;Count number observations group ;Count number observations group ;Remove groupingRemove groupinggroup_by() result surface level changes dataset, rather, changes underlying structure groups specified, whatever functions called next performed separately level grouping variable. grouping remains object created important remove ungroup() avoid future operations object unknowingly performed groups.code therefore counts number observations group variable language. just need total number observations, remove group_by() ungroup() lines, perform operation whole dataset, rather groups:","code":"\ndat %>%\n  group_by(language) %>%\n  count() %>%\n  ungroup()\ndat %>%\n  count()"},{"path":"session-2-1.html","id":"summarise","chapter":"5 Session 2.1","heading":"5.3 Summarise","text":"Similarly, may wish calculate mean age (SD) sample can using function summarise() dplyr tidyverse package.code produces summary data form column named mean_age contains result calculating mean variable age. creates sd_age standard deviation. Finally, uses function n() add number values used calculate statistic column named n_values - useful sanity check whenever make summary statistics.Note code save result operation, simply output result console. wish save future use, can store object using <- notation print later typing object name.Finally, group_by() function work way calculating summary statistics -- output function called group_by() produced level grouping variable.","code":"\ndat %>%\n  summarise(mean_age = mean(age),\n            sd_age = sd(age),\n            n_values = n())\nage_stats <- dat %>%\n  summarise(mean_age = mean(age),\n            sd_age = sd(age),\n            n_values = n())\ndat %>%\n  group_by(language) %>%\n  summarise(mean_age = mean(age),\n            sd_age = sd(age),\n            n_values = n()) %>%\n  ungroup()"},{"path":"session-2-1.html","id":"pipes-first","chapter":"5 Session 2.1","heading":"5.4 Pipes","text":"go , take quick detour formally introduce pipe. Pipes allow send output one function straight another function. Specifically, send result function %>% first argument function %>%. can useful translate pipe \"\". easier show tell, look example.Notice summarise() longer needs first argument data table, pulled pipe. power pipe may obvious now, soon prove worth.","code":"\n# without pipe\nrt_pipes <- summarise(dat,\n                      mean_rt = mean(rt_word), \n                      median_rt = median(rt_word))\n\n# with pipe\nrt_pipes <- dat %>% \n  summarise(mean_rt = mean(rt_word), \n            median_rt = median(rt_word))"},{"path":"session-2-1.html","id":"alternatives","chapter":"5 Session 2.1","heading":"5.5 Alternatives","text":"method used pure tidyverse. good thing approach output creates easy work can used range different functions (example, can calculate table descriptives use data set ggplot). However, lots alternatives useful know ) see try Google help b) easier additional functionality.","code":""},{"path":"session-2-1.html","id":"base-r","chapter":"5 Session 2.1","heading":"5.5.1 Base R","text":"Rather embedding functions within summarise() can call summary functions straight Base R. also clear $ notation . dollar sign allows select items object, columns table. left-hand side object, right-hand side item. code, calculating mean rt_nonword column present data set dat_long.Base R also contains function summary():","code":"\nmean(dat_long$rt)\nmedian(dat_long$rt)## [1] 434.703\n## [1] 412.5891\nsummary(dat)##       id                 age               language     rt_word     \n##  Length:100         Min.   :18.00   monolingual:55   Min.   :256.3  \n##  Class :character   1st Qu.:24.00   bilingual  :45   1st Qu.:322.6  \n##  Mode  :character   Median :28.50                    Median :353.8  \n##                     Mean   :29.75                    Mean   :353.6  \n##                     3rd Qu.:33.25                    3rd Qu.:379.5  \n##                     Max.   :58.00                    Max.   :479.6  \n##    rt_nonword       acc_word       acc_nonword   \n##  Min.   :327.3   Min.   : 89.00   Min.   :76.00  \n##  1st Qu.:438.8   1st Qu.: 94.00   1st Qu.:82.75  \n##  Median :510.6   Median : 95.00   Median :85.00  \n##  Mean   :515.8   Mean   : 95.01   Mean   :84.90  \n##  3rd Qu.:582.9   3rd Qu.: 96.25   3rd Qu.:88.00  \n##  Max.   :706.2   Max.   :100.00   Max.   :93.00"},{"path":"session-2-1.html","id":"psychdescribe","chapter":"5 Session 2.1","heading":"5.5.2 psych::describe()","text":"function describe() psych incredibly useful quickly produces range descriptive statistics, including standard error otherwise faff compute R base function standard error like e.g., sd().can see, describe() computes stats variables data set probably need. Instead, can use select() tidyverse select columns want describe pass describe(). may also want drop columns default describe() table can select() - hopefully power %>% begins obvious.Finally, describe() tidyverse, use group_by() however, also grouped version, describeBy().object creates different created far. Rather single data frame tibble, creates list. Lists can contain multiple objects, datasets, data types mean little bit harder work need use $ notation pull specific objects list can manipulate .want get rid row contains language (descriptives informative) requires little bit extra wrangling. first column actually stored rownames rather column first convert . row names column, can use filter() get remove .","code":"\ndescribe(dat_long)\ndescribe_table <- dat_long %>%\n  select(rt, acc)%>%\n  describe() %>%\n  select(-vars)\ndescribebytable <- dat_long %>%\n  select(language, rt, acc) %>%\n  describeBy(group = \"language\") \ndescribebytable$monolingual %>%\n  select(-vars) \nrownames_to_column(describebytable$monolingual, var = \"names\")"},{"path":"session-2-1.html","id":"glossary-intro","chapter":"5 Session 2.1","heading":"5.6 Glossary","text":"","code":""},{"path":"session-2-1.html","id":"resources-summary","chapter":"5 Session 2.1","heading":"5.7 Further resources","text":"Data transformation cheat sheetChapter 5: Data Transformation R Data ScienceTidy Text","code":""},{"path":"session-2-2.html","id":"session-2-2","chapter":"6 Session 2.2","heading":"6 Session 2.2","text":"","code":""},{"path":"session-2-2.html","id":"test-your-understanding-1","chapter":"6 Session 2.2","heading":"6.1 Test your understanding 1","text":"small data table.geom use plot population 5 countries? geom_bargeom_colWhat mapping use?\n\naes(x = country, y = population)aes(x = population, y = country)aes(x = country)aes(x = island)aes(y = population)\ngeom use plot number countries island? geom_bargeom_colWhat mapping use?\n\naes(x = country, y = population)aes(x = population, y = country)aes(x = country)aes(x = island)aes(y = population)\n","code":""},{"path":"session-2-2.html","id":"test-your-understanding-2","chapter":"6 Session 2.2","heading":"6.2 Test your understanding 2","text":"Imagine table population country world columns country population. just look 76 countries populations less million.kind plot ? geom_histogramgeom_freqpolygeom_densityWhat kind plot B? geom_histogramgeom_freqpolygeom_densityWhat kind plot C? geom_histogramgeom_freqpolygeom_densityHow set mapping plots?\n\naes(x = country, y = population)aes(x = population, y = country)aes(x = population)aes(x = population, y = count)\nbinwidth histogram? 1100100K1M","code":""},{"path":"session-2-2.html","id":"test-your-understanding-3","chapter":"6 Session 2.2","heading":"6.3 Test your understanding 3","text":"create plot ? geom_box()geom_boxplot()geom_violin()geom_violinplot()create plot B? geom_box()geom_boxplot()geom_violin()geom_violinplot()mapping look like plots?\n\naes(x = employee_id, y = call_time, colour = call_time)aes(x = employee_id, y = call_time, colour = employee_id)aes(x = employee_id, y = call_time, fill = call_time)aes(x = employee_id, y = call_time, fill = employee_id)\nemployee tends longest calls? e01e02e03e04e05e06e07e08e09e10Which employee record longest call? e01e02e03e04e05e06e07e08e09e10","code":""},{"path":"session-2-2.html","id":"exercises","chapter":"6 Session 2.2","heading":"6.4 Exercises","text":"consolidate learned far, use built-starwars data set create following:histogram heightsA scatterplot height v mass line best fitA bar chart counts genderThen use built-ingss_cat data set create:grouped density plot age marital statusA frequency plot age marital statusA violin-boxplot age marital statusFinally, pick two favourite plots , spend time adjusting aesthetics (colours, themes, labels etc.), combine using patchwork. Twitter, share #PsyTeachR tag emilynordmann.","code":"\n# load data\ndata(\"starwars\")\n\n# histogram\nggplot(starwars, aes(x = height)) +\n  geom_histogram()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 6 rows containing non-finite values (stat_bin).\n# scatterplot\nggplot(starwars, aes(x = height, y = mass)) +\n  geom_point() +\n  geom_smooth()## `geom_smooth()` using method = 'loess' and formula 'y ~ x'## Warning: Removed 28 rows containing non-finite values (stat_smooth).## Warning: Removed 28 rows containing missing values (geom_point).\n# bar chart\nggplot(starwars, aes(x = gender)) +\n  geom_bar()\n# load data\ndata(\"gss_cat\")\n\n# grouped density\nggplot(gss_cat, aes(x = age, fill = marital)) +\n  geom_density(alpha = .6)## Warning: Removed 76 rows containing non-finite values (stat_density).\n# frequency plot\nggplot(gss_cat, aes(x = age, colour = marital)) +\n  geom_freqpoly()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 76 rows containing non-finite values (stat_bin).\n# violin-boxplot\nggplot(gss_cat, aes(x = marital, y = age)) +\n  geom_violin() +\n  geom_boxplot(width = .2)## Warning: Removed 76 rows containing non-finite values (stat_ydensity).## Warning: Removed 76 rows containing non-finite values (stat_boxplot)."},{"path":"session-3-1.html","id":"session-3-1","chapter":"7 Session 3.1","heading":"7 Session 3.1","text":"","code":""},{"path":"session-3-1.html","id":"set-up-2","chapter":"7 Session 3.1","heading":"7.1 Set-up","text":"Open Workshop project following:Create save new R Markdown document named Session 3.1. get rid default template text line 11 onwards.Download example data file data folder:\nbudget.csv.Download Data transformation cheat sheet.","code":""},{"path":"session-3-1.html","id":"wrangling-functions","chapter":"7 Session 3.1","heading":"7.2 Wrangling functions","text":"Data wrangling refers process cleaning, transforming, restructuring data get format need analysis something spend awful lot time . lot data wrangling covered six functions dplyr package loaded part tidyverse: select, filter, arrange, mutate, summarise, group_by. covered briefly already repeating functions different dataset help.worth highlighting session going cover common functions common uses said functions. However, dplyr (packages beyond ) huge number additional wrangling functions function many different arguments. Essentially, think able wrangle data particular way explicitly shown , almost certainly can, might just take bit Googling find .use small example table sales, expenses, satisfaction two years four regions two products. load data, use glimpse(budget) View(budget) get familiar data.","code":"\nlibrary(tidyverse)\nbudget <- read_csv(\"data/budget.csv\")"},{"path":"session-3-1.html","id":"select","chapter":"7 Session 3.1","heading":"7.2.1 Select","text":"can select subset columns (variables) table make easier view prepare table display. can also select columns new order.","code":""},{"path":"session-3-1.html","id":"by-name-or-index","chapter":"7 Session 3.1","heading":"7.2.1.1 By name or index","text":"can select columns name number (sometimes referred column index). Selecting number can useful column names long complicated.can select column individually, separated commas (e.g., region, sales_2019) can also select columns one another separating colon (e.g., sales_2019:expenses_2020).colon notation can much faster need type individual variable name, make sure know order columns always check output make sure selected intended.can rename columns time selecting setting new_name = old_col.","code":"\n# select single column by name\nproduct_dat <- budget %>% select(product) \n\n# select single column by number\nproduct_dat <- budget %>% select(2) \n# select columns individually\nsales2019 <- budget %>% select(region, product, sales_2019)\n\n# select columns with colon\nsales2019 <- budget %>% select(region:sales_2019)\nregions <- budget %>% select(`Sales Region` = 1, 3:6)\n\nhead(regions, 2)"},{"path":"session-3-1.html","id":"un-selecting-columns","chapter":"7 Session 3.1","heading":"7.2.1.2 Un-selecting columns","text":"can select columns either telling R ones want keep previous examples, specifying ones want exclude using minus symbol un-select columns. can also use colon notation de-select columns, need put parentheses around span first, e.g., -(sales_2019:expenses_2020), -sales_2019:expenses_2020.","code":"\n# de-select individual columns\nsales <- budget %>% select(-expenses_2019, -expenses_2020)\n\n# de-select a range of columns\nsales <- budget %>% select(-(expenses_2019:expenses_2020))"},{"path":"session-3-1.html","id":"select-helpers","chapter":"7 Session 3.1","heading":"7.2.1.3 Select helpers","text":"Finally, can select columns based criteria column names.","code":""},{"path":"session-3-1.html","id":"filter","chapter":"7 Session 3.1","heading":"7.2.2 Filter","text":"Whilst select() chooses columns want retain, filter() chooses rows retain matching row column criteria.can filter single criterion. criterion can rows certain column's value matches character value (e.g., \"North\") number (e.g., 9003). can also result logical equation (e.g., keep rows specific column value larger certain value). criterion checked row, result FALSE, row removed. can reverse equations specifying != ! means \"\".Remember use == = check two things equivalent. single = assigns right-hand value left-hand variable (much like <- operator).can also select multiple criteria separating commas (rows kept match criteria). Additionally, can use & (\"\") | (\"\") create complex criteria.want filter retain multiple specific values variable, match operator (%%) used rather | (). ! can also used combination , placed variable name.Finally, can also pass many functions filter. example, package stringr loaded part tidyverse contains many different functions working strings (character data). example, use str_detect() retain rows customer satisfaction rating includes word \"high\"Note str_detect() case sensitive return values \"High\" \"HIGH\". can use function tolower() toupper() convert string lowercase uppercase search substring need case-insensitive matching.filter() incredibly powerful can allow select specific subsets data. , also quite dangerous start combining multiple criteria operators, easy accidentally specify something slightly different intended. Always check output. small dataset, can eyeball see looks right. larger dataset, may wish compute summary statistics count number groups/observations variable verify filter correct. level expertise coding can substitute knowing checking data.","code":"\n# select all rows where region equals North\nbudget %>% filter(region == \"North\")\n\n# select all rows where expenses_2020 were exactly equal to 200\nbudget %>% filter(expenses_2020 == 200)\n\n# select all rows where sales_2019 was more than 100\nbudget %>% filter(sales_2019 > 100)\n\n# everything but the North\nbudget %>% filter(region != \"North\")\n# regions and products with profit in both 2019 and 2020\nprofit_both <- budget %>% \n  filter(\n    sales_2019 > expenses_2019,\n    sales_2020 > expenses_2020\n  )\n\n# the same as above, using & instead of a comma\nprofit_both <- budget %>% \n  filter(\n    sales_2019 > expenses_2019 &\n    sales_2020 > expenses_2020\n  )\n\n# regions and products with profit in 2019 or 2020\nprofit_either <- budget %>% \n  filter(\n    sales_2019 > expenses_2019 |\n    sales_2020 > expenses_2020\n  )\n\n# 2020 profit greater than 1000\nprofit_1000 <- budget %>%\n  filter(sales_2020 - expenses_2020 > 1000)\n# retain any rows where region is north or south, and where product equals widget\nbudget %>%\n  filter(region %in% c(\"North\", \"South\"),\n         product == \"widgets\")\n\n# retain any rows where the region is not east or west, and where the product does not equal gadgets\nbudget %>%\n  filter(!region %in% c(\"East\", \"West\"),\n         product != \"gadgets\")\nbudget %>%\n  filter(str_detect(satisfaction_2019, \"high\"))"},{"path":"session-3-1.html","id":"arrange","chapter":"7 Session 3.1","heading":"7.2.3 Arrange","text":"can sort dataset using arrange(). find needing sort data R much less Excel, since need rows next order , example, calculate group means. arrange() can useful preparing data display tables. arrange() works character data sort alphabetically, well numeric data default ascending order (smallest largest). Reverse order using desc().","code":"\n# arranging the table \n# first by product in alphabetical order\n# then by \"region\" in reverse alphabetical order\nbudget %>%\n  arrange(product, desc(region))"},{"path":"session-3-1.html","id":"mutate","chapter":"7 Session 3.1","heading":"7.2.4 Mutate","text":"function mutate() allows add new columns change existing ones overwriting using syntax new_column = operation. can add one column mutate function separating columns comma. make new column, can use column definitions. example, creation profit uses column expenses, created .mutate() can also used conjunction functions Boolean operators. example, can add another column budget2 states whether profit returned year overwrite product variable factor. Just like used Boolean expressions filter, evaluate equation return TRUE FALSE depending whether observation meets criteria.can overwrite column giving new column name old column (see region product) . Make sure mean trying use old column value redefine .can also use case_when() specify values return, rather defaulting TRUE FALSE:Use recode values:combine different criteria:Just like filter(), mutate() incredibly powerful scope can create far beyond can cover book.","code":"\nbudget2 <- budget %>%\n  mutate(\n    sales = sales_2019 + sales_2020,\n    expenses = expenses_2019 + expenses_2020,\n    profit = sales - expenses,\n    region = paste(region, \"Office\")\n  )\nbudget2 <- budget2 %>%\n  mutate(profit_category = profit > 0,\n         product = as.factor(product))\nbudget3 <- budget2 %>%\n  mutate(profit_category = case_when(profit > 0 ~ \"PROFIT\",\n                                     profit < 0 ~ \"NO PROFIT\"))\n# create a column where people get a bonus if customer satisfaction was overall high or very high\n\nbonus <- budget3 %>%\n  mutate(bonus_2019 = case_when(satisfaction_2019 %in% c(\"very low\", \"low\", \"neutral\") ~ \"no bonus\",\n                                satisfaction_2019 %in% c(\"high\", \"very high\") ~ \"bonus\"))\n# new management takes over - people only get a bonus if customer satisfaction was overall high or very high AND if a profit was returned\n\nbonus2 <- budget3 %>%\n  mutate(bonus_2020 = case_when(satisfaction_2020 == \"high\" & \n                                  profit_category == \"PROFIT\" ~ \"bonus\",\n                                satisfaction_2020 == \"very high\" & \n                                  profit_category == \"PROFIT\" ~ \"bonus\",\n                                TRUE ~ \"No bonus\")) # set all other values to \"no bonus\""},{"path":"session-3-1.html","id":"dplyr-summarise","chapter":"7 Session 3.1","heading":"7.2.5 Summarise","text":"already used summarise() quick recap.say want determine min max sales year, can using summarise(). return table names variables (columns) provide LHS (e.g., mean_2019) values cell result calculation specified RHS. (better way use pivot_longer() reshape data ignore now).","code":"\nsales <- budget %>%\n  summarise(min_2019 = min(sales_2019),\n            min_2020 = min(sales_2020),\n            max_2019 = max(sales_2019),\n            max_2020 = max(sales_2020))\n\nsales"},{"path":"session-3-1.html","id":"dplyr-groupby","chapter":"7 Session 3.1","heading":"7.2.6 Group By","text":"also already looked group_by() another example calculate min max sales figures product - note summarise code change, just add call group_by() :Note can use wrangling functions summary table, example:","code":"\nsales_prod <- budget %>%\n  group_by(product) %>%\n  summarise(min_2019 = min(sales_2019),\n            min_2020 = min(sales_2020),\n            max_2019 = max(sales_2019),\n            max_2020 = max(sales_2020)) %>%\n  ungroup()\n\nsales_prod\n# arrange by maximum profit\nsales_prod %>%\n  arrange(desc(min_2019))\n\n# filter out gadgets\nsales_prod %>%\n  filter(product != \"gadgets\")"},{"path":"session-3-1.html","id":"missing-values","chapter":"7 Session 3.1","heading":"7.3 Missing values","text":"control data, always best keep missing values empty cells rather denoting missingness word implausible number. used \"missing\" rather leaving cell empty, entire variable read character data, means able perform mathematical operations like calculating mean. use implausible number (0 999 common), risk values included calculations real numbers.However, often control data come us, run fix . example, going revert use lexical decision dataset session 2.1This dataset missing values introduce pretend imaginary computer used record reaction times record data RTs 350ms student intern hired quite follow instructions properly instead leaving cells blank, entered missing data 0.Somewhat unintuitively, different types NAs surface tell case_when() one use (NA_real_, NA_complex, NA_character_, NA_integer_), case, rt real number.","code":"\ndat <- read_csv(file = \"data/ldt_data.csv\") %>%\n  mutate(language = factor(\n  x = language, # column to translate\n  levels = c(1, 2), # values of the original data in preferred order\n  labels = c(\"monolingual\", \"bilingual\") # labels for display\n))\n\ndat_long <- pivot_longer(data = dat, \n                         cols = rt_word:acc_nonword, \n                         names_sep = \"_\", \n                         names_to = c(\"dv_type\", \"condition\"),\n                         values_to = \"dv\") %>%\n  pivot_wider(names_from = \"dv_type\", \n              values_from = \"dv\")\ndat_missing <- dat_long %>%\n  mutate(rt = case_when(rt < 350 ~ NA_real_, # when rt is less than 350 replace with NA\n                        TRUE ~ rt), # otherwise, use the value in the column rt (i.e., no change)\n         acc = case_when(id %in% c(\"S001\", \"S002\", \"S003\", \"S004\", \"S005\") ~ 0, # when id is one of these listed, replace with 0\n                         TRUE ~ acc)) # otherwise use the value in the column acc"},{"path":"session-3-1.html","id":"ignore-missing-values","chapter":"7 Session 3.1","heading":"7.3.0.1 Ignore missing values","text":"deal rt data first. try compute mean rt returns NA. NA basically means \"know\", sum 100 \"know\" \"know\", 100. However, calculating means, often want just ignore missing values. Set na.rm = TRUE summary function remove missing values calculating.","code":"\n# code that will return NA\ndat_missing %>%\n  summarise(mean_rt = mean(rt))\n\n# ignore missing values to return mean\ndat_missing %>%\n  summarise(mean_rt = mean(rt, na.rm = TRUE))"},{"path":"session-3-1.html","id":"convert-values-to-na","chapter":"7 Session 3.1","heading":"7.3.0.2 Convert values to NA","text":"accuracy, compute mean can see different problem - return number actually wrong including 0s calculation mean. important lesson always check data - jsut code runs mean right.fix need convert 0s NAs (create missing data rt) using case_when():can now calculate accuracy accurately adding na.rm = TRUE:","code":"\ndat_missing %>%\n  summarise(mean_acc = mean(acc))\ndat_fixed <- dat_missing %>%\n  mutate(acc = case_when(acc == 0 ~ NA_real_,\n                         TRUE ~ acc))\ndat_fixed %>%\n  summarise(mean_acc = mean(acc, na.rm = TRUE))"},{"path":"session-3-1.html","id":"count-missing-values","chapter":"7 Session 3.1","heading":"7.3.0.3 Count missing values","text":"want find many missing non-missing values column, use .na() function get logical vector whether value missing, use sum() count many values TRUE mean() calculate proportion TRUE values.","code":"\ndat_missing %>%\n  group_by(condition) %>%\n  summarise(\n    n_valid = sum(!is.na(rt)),\n    n_missing = sum(is.na(rt)),\n    prop_missing = mean(is.na(rt))\n  )"},{"path":"session-3-1.html","id":"omit-missing-values","chapter":"7 Session 3.1","heading":"7.3.0.4 Omit missing values","text":"may also want remove rows missing values work complete datasets. drop_na() remove row missing observation. can use drop_na() entire dataset remove row missing value, can specify remove rows missing specific value.Missing data can quite difficult deal depending represented. always, amount coding expertise can make understanding structure idiosyncrasies data.","code":"\n# remove any rows with any missing values\ncomplete_data <- dat_missing %>%\n  drop_na()\n\n# remove any rows that are missing a value for sales\ncomplete_rt <- dat_missing %>%\n  drop_na(rt)"},{"path":"session-3-1.html","id":"glossary-3-1","chapter":"7 Session 3.1","heading":"7.4 Glossary","text":"","code":""},{"path":"session-3-1.html","id":"resources-3-1","chapter":"7 Session 3.1","heading":"7.5 Further resources","text":"Data transformation cheat sheetChapter 5: Data Transformation R Data ScienceChapter 19: Functions R Data ScienceIntroduction stringr","code":""},{"path":"session-3-2.html","id":"session-3-2","chapter":"8 Session 3.2","heading":"8 Session 3.2","text":"","code":""},{"path":"session-3-2.html","id":"set-up-3","chapter":"8 Session 3.2","heading":"8.1 Set-up","text":"Open Workshop project following:Create save new R Markdown document named Session 3.2. get rid default template text line 11 onwards.Download Data transformation cheatsheet.Create new code chunk load tidyverse.","code":""},{"path":"session-3-2.html","id":"joins-data","chapter":"8 Session 3.2","heading":"8.2 Loading data","text":"data want report visualise often one file (one tab excel file). might need join participant demographic information experimental data, score questionnaire responses according scoring ket.demo, rather loading data, create two small data tables scratch using tibble() function.customers id, city postcode five customers 1-5.1:5 fill variable id integers 1 5.city code use c() function enter multiple strings. Note entry contained within quotation marks, apart missing data, recorded NA.entering data like , important order variable matches . number 1 correspond \"Port Ellen\" \"PA42 7DU\".\nTable 8.1: Demo customers table.\norders customer id number items ordered. customers previous table orders, one order, customer table.\nTable 8.2: Demo orders table.\n","code":"\ncustomers <- tibble(\n  id = 1:5,\n  city = c(\"Port Ellen\", \"Dufftown\", NA, \"Aberlour\", \"Tobermory\"),\n  postcode = c(\"PA42 7DU\", \"AB55 4DH\", NA, \"AB38 7RY\", \"PA75 6NR\")\n)\norders <- tibble(\n  id = c(2, 3, 4, 4, 5, 5, 6, 6, 7),\n  items = c(10, 18, 21, 23, 9, 11, 11, 12, 3)\n)"},{"path":"session-3-2.html","id":"mutating-joins","chapter":"8 Session 3.2","heading":"8.3 Mutating Joins","text":"Mutating joins act like dplyr::mutate() function add new columns one table based values another table.mutating joins basic syntax:****_join(x, y, = NULL, suffix = c(\".x\", \".y\"))x = first (left) tabley = second (right) tableby = columns match . leave blank, match columns names two tables.suffix = columns name two tables, joining , get suffix make unambiguous. defaults \".x\" \".y\", can change something meaningful.can leave argument matching columns name, good practice always specify code robust changes loaded data.","code":""},{"path":"session-3-2.html","id":"left_join","chapter":"8 Session 3.2","heading":"8.3.1 left_join()","text":"left_join keeps data first (left) table adds anything matches second (right) table. right table one match row left table, one row joined table (see ids 4 5).order specify tables matters, code reversed order result rows orders table joined matching rows customers table.","code":"\nleft_data <- left_join(customers, orders, by = \"id\")\nleft_data\nleft2_data <- left_join(orders, customers, by = \"id\")\nleft2_data"},{"path":"session-3-2.html","id":"right_join","chapter":"8 Session 3.2","heading":"8.3.2 right_join()","text":"right_join keeps data second (right) table joins anything matches first (left) table.table information left_join(orders, customers, = \"id\"), columns different order (left table, right table).","code":"\nright_data <- right_join(customers, orders, by = \"id\")\nright_data"},{"path":"session-3-2.html","id":"inner_join","chapter":"8 Session 3.2","heading":"8.3.3 inner_join()","text":"inner_join returns rows match tables. Changing order tables change order columns, rows kept.","code":"\ninner_data <- inner_join(customers, orders, by = \"id\")\ninner_data"},{"path":"session-3-2.html","id":"full_join","chapter":"8 Session 3.2","heading":"8.3.4 full_join()","text":"full_join lets join rows two tables keeping information tables. row match table, table's column values set NA.","code":"\nfull_data <- full_join(customers, orders, by = \"id\")\nfull_data"},{"path":"session-3-2.html","id":"filtering-joins","chapter":"8 Session 3.2","heading":"8.4 Filtering Joins","text":"Filtering joins act like dplyr::filter() function keep remove rows data one table based values another table. result filtering join contain rows left table number fewer rows left table.","code":""},{"path":"session-3-2.html","id":"semi_join","chapter":"8 Session 3.2","heading":"8.4.1 semi_join()","text":"semi_join returns rows left table matching values right table, keeping just columns left table.Unlike inner join, semi join never duplicate rows left table one matching row right table.Order matters semi join.","code":"\nsemi_data <- semi_join(customers, orders, by = \"id\")\nsemi_data\nsemi2_data <- semi_join(orders, customers, by = \"id\")\nsemi2_data"},{"path":"session-3-2.html","id":"anti_join","chapter":"8 Session 3.2","heading":"8.4.2 anti_join()","text":"anti_join return rows left table matching values right table, keeping just columns left table.Order matters anti join.","code":"\nanti_data <- anti_join(customers, orders, by = \"id\")\nanti_data\nanti2_data <- anti_join(orders, customers, by = \"id\")\nanti2_data"},{"path":"session-3-2.html","id":"multiple-joins","chapter":"8 Session 3.2","heading":"8.5 Multiple joins","text":"****_join() functions two-table verbs, , can join together two tables time. However, may often need join together multiple tables. , simply need add additional joins. can creating intermediate object efficiently using pipe.every stage analysis check output ensure created intended create, particularly true joins. familiar enough data routine checks using functions like glimpse(), str(), summary() rough idea join result . least, know whether joined object result fewer variables observations.multi-line join like piped example, build code check output stage.","code":"\n# create a table of overall customer satisfaction scores\nsatisfaction <- tibble(\n  id = 1:5,\n  satisfaction = c(4, 3, 2, 3, 1)\n)\n\n# perform the initial join\njoin_1 <- left_join(customers, orders, by = \"id\")\n\n# perform the second join on the new object\njoin_2 <- left_join(join_1, satisfaction, \n                    by = \"id\")\n# more efficient method using the pipe\npipe_join <- customers %>%\n  left_join(orders, by = \"id\") %>%\n  left_join(satisfaction, by = \"id\")"},{"path":"session-3-2.html","id":"binding-joins","chapter":"8 Session 3.2","heading":"8.6 Binding Joins","text":"Binding joins bind one table another adding rows columns together.","code":""},{"path":"session-3-2.html","id":"bind_rows","chapter":"8 Session 3.2","heading":"8.6.1 bind_rows()","text":"can combine rows two tables bind_rows.add customer data customers 6-9 bind original customer table.columns just names, order. columns differ two tables just NA values entries table.row duplicated two tables (like id 5 ), row also duplicated resulting table. tables exact columns, can use union() (see Section 8.7.2) avoid duplicates.","code":"\nnew_customers <- tibble(\n  id = 6:9,\n  city = c(\"Falkirk\", \"Ardbeg\", \"Doogal\", \"Kirkwall\"),\n  postcode = c(\"FK1 4RS\", \"PA42 7EA\", \"G81 4SJ\", \"KW15 1SE\")\n)\n\nbindr_data <- bind_rows(customers, new_customers)\nbindr_data\nnew_customers <- tibble(\n  id = 5:9,\n  postcode = c(\"PA75 6NR\", \"FK1 4RS\", \"PA42 7EA\", \"G81 4SJ\", \"KW15 1SE\"),\n  city = c(\"Tobermory\", \"Falkirk\", \"Ardbeg\", \"Doogal\", \"Kirkwall\"),\n  new = c(1,2,3,4,5)\n)\n\nbindr2_data <- bind_rows(customers, new_customers)\nbindr2_data"},{"path":"session-3-2.html","id":"bind_cols","chapter":"8 Session 3.2","heading":"8.6.2 bind_cols()","text":"can merge two tables number rows using bind_cols. useful two tables number rows exact order.advantage bind_cols() mutating join tables IDs join rely solely order. Otherwise, use mutating join (four mutating joins result output rows table exactly one match table).","code":"\nnew_info <- tibble(\n  colour = c(\"red\", \"orange\", \"yellow\", \"green\", \"blue\")\n)\n\nbindc_data <- bind_cols(customers, new_info)\nbindc_data "},{"path":"session-3-2.html","id":"set-operations","chapter":"8 Session 3.2","heading":"8.7 Set Operations","text":"Set operations compare two tables return rows match (intersect), either table (union), one table (setdiff).","code":""},{"path":"session-3-2.html","id":"intersect","chapter":"8 Session 3.2","heading":"8.7.1 intersect()","text":"dplyr::intersect() returns rows two tables match exactly. columns order, names.forgotten load dplyr tidyverse, base R also base::intersect() function work like dplyr::intersect(). error message can confusing looks something like :","code":"\nnew_customers <- tibble(\n  id = 5:9,\n  postcode = c(\"PA75 6NR\", \"FK1 4RS\", \"PA42 7EA\", \"G81 4SJ\", \"KW15 1SE\"),\n  city = c(\"Tobermory\", \"Falkirk\", \"Ardbeg\", \"Doogal\", \"Kirkwall\")\n)\n\nintersect_data <- intersect(customers, new_customers)\nintersect_data\nbase::intersect(customers, new_customers)## Error:\n## ! Must subset rows with a valid subscript vector.\n## i Logical subscripts must match the size of the indexed input.\n## x Input has size 5 but subscript `!duplicated(x, fromLast = fromLast, ...)` has size 0."},{"path":"session-3-2.html","id":"union","chapter":"8 Session 3.2","heading":"8.7.2 union()","text":"dplyr::union() returns rows tables, removing duplicate rows, unlike bind_rows().forgotten load dplyr tidyverse, base R also base::union() function. usually get error message, output expect.","code":"\nunion_data <- union(customers, new_customers)\nunion_data\nbase::union(customers, new_customers)## [[1]]\n## [1] 1 2 3 4 5\n## \n## [[2]]\n## [1] \"Port Ellen\" \"Dufftown\"   NA           \"Aberlour\"   \"Tobermory\" \n## \n## [[3]]\n## [1] \"PA42 7DU\" \"AB55 4DH\" NA         \"AB38 7RY\" \"PA75 6NR\"\n## \n## [[4]]\n## [1] 5 6 7 8 9\n## \n## [[5]]\n## [1] \"PA75 6NR\" \"FK1 4RS\"  \"PA42 7EA\" \"G81 4SJ\"  \"KW15 1SE\"\n## \n## [[6]]\n## [1] \"Tobermory\" \"Falkirk\"   \"Ardbeg\"    \"Doogal\"    \"Kirkwall\""},{"path":"session-3-2.html","id":"setdiff","chapter":"8 Session 3.2","heading":"8.7.3 setdiff()","text":"dplyr::setdiff returns rows first table, second table.Order matters setdiff.forgotten load dplyr tidyverse, base R also base::setdiff() function. usually get error message, output might expect base::setdiff() expects columns order, id 5 registers different two tables.","code":"\nsetdiff_data <- setdiff(customers, new_customers)\nsetdiff_data\nsetdiff2_data <- setdiff(new_customers, customers)\nsetdiff2_data\nbase::setdiff(customers, new_customers)"},{"path":"session-3-2.html","id":"conflicting-variable-types","chapter":"8 Session 3.2","heading":"8.8 Conflicting variable types","text":"import create data, R best set column appropriate data type. However, sometimes gets wrong sometimes something way data encoded original spreadsheet causes data type different expected. joining datasets common columns, important variable names identical, data type variables identical.recreate new_customers dataset time, specify id character variable.try join dataset datasets id stored numeric variable, produce error.goes bind_rows():One method change variable types use .*** functions. type . code chunk, see huge number functions transforming variables datasets different types. Exactly one need depend data , commonly used ones :.numeric() - convert variable numeric. Useful variable real numbers encoded character. values turned numbers (e.g., word \"missing\" cells data ), returned NA..factor() - convert variable factor. can set factor levels labels manually, use default order (alphabetical)..character() - convert variable character data..tibble() .data.frame() - convert list object (variable) tibble data frame (two different table formats). actually relevant discussing , useful one aware sometimes run issues get error specifically requests data tibble data frame type can use function overwrite object.use functions variable can use mutate() overwrite variable variable new data type:done , joins now work:","code":"\nnew_customers2 <- tibble(\n  id = as.character(5:9),\n  postcode = c(\"PA75 6NR\", \"FK1 4RS\", \"PA42 7EA\", \"G81 4SJ\", \"KW15 1SE\"),\n  city = c(\"Tobermory\", \"Falkirk\", \"Ardbeg\", \"Doogal\", \"Kirkwall\")\n)\nstr(new_customers2)## tibble [5 x 3] (S3: tbl_df/tbl/data.frame)\n##  $ id      : chr [1:5] \"5\" \"6\" \"7\" \"8\" ...\n##  $ postcode: chr [1:5] \"PA75 6NR\" \"FK1 4RS\" \"PA42 7EA\" \"G81 4SJ\" ...\n##  $ city    : chr [1:5] \"Tobermory\" \"Falkirk\" \"Ardbeg\" \"Doogal\" ...\ninner_join(customers, new_customers2)## Joining, by = c(\"id\", \"city\", \"postcode\")## Error in `inner_join()`:\n## ! Can't join on `x$id` x `y$id` because of incompatible types.\n## i `x$id` is of type <integer>>.\n## i `y$id` is of type <character>>.\nbind_rows(customers, new_customers2)## Error in `bind_rows()`:\n## ! Can't combine `..1$id` <integer> and `..2$id` <character>.\nnew_customers2 <- new_customers2 %>%\n  mutate(id = as.numeric(id))\ninner_join(orders, new_customers2)## Joining, by = \"id\""},{"path":"session-3-2.html","id":"glossary-3-2","chapter":"8 Session 3.2","heading":"8.9 Glossary","text":"","code":""},{"path":"session-3-2.html","id":"resources-3-2","chapter":"8 Session 3.2","heading":"8.10 Further resources","text":"Data transformation cheatsheetChapter 13: Relational Data R Data Science","code":""},{"path":"session-4-1.html","id":"session-4-1","chapter":"9 Session 4.1","heading":"9 Session 4.1","text":"chapter use simulated version dataset adapted Miller Haden (2013), Chapter 11, looking relationship four variables: reading ability, intelligence (IQ), number minutes per week spent reading home (Home); number minutes per week spent watching TV home (TV).","code":""},{"path":"session-4-1.html","id":"set-up-4","chapter":"9 Session 4.1","heading":"9.1 Set-up","text":"Open Workshop project following:Create save new R Markdown document named Session 4.1. get rid default template text line 11 onwards.Load required packages data .","code":"\nlibrary(patchwork)\nlibrary(correlation)\nlibrary(psych)\nlibrary(performance)\nlibrary(tidyverse)\nmh <- read_csv(\"https://raw.githubusercontent.com/emilynordmann/workshop-intro-to-r/main/book/data/reading_iq.csv\")"},{"path":"session-4-1.html","id":"corr-a2","chapter":"9 Session 4.1","heading":"9.2 Look at the data","text":"loaded data correctly able look one various methods looked already.Look data using head() function see following:can see, five columns :participant number (Participant),Reading Ability score (Abil),Intelligence score (IQ),number minutes spent reading Home per week (Home),number minutes spent watching TV per week (TV).focus Reading Ability IQ practice can look relationships optional exercises.probable hypothesis Intelligence predicts Reading Ability test performing correlation linear regression","code":""},{"path":"session-4-1.html","id":"descriptive-statistics-and-visualisation","chapter":"9 Session 4.1","heading":"9.3 Descriptive statistics and visualisation","text":"First, computer descriptive statistics variables interest using summarise() done previously.can also plot relationship two variables scatterplot using ggplot(). use geom_jiter() rather geom_point() fe overlaping scores.","code":"\ndescriptives <- summarise(mh, \n                          Abil_mean = mean(Abil),\n                          Abil_SD = sd(Abil),\n                          IQ_mean = mean(IQ),\n                          IQ_SD = sd(IQ))\n\ndescriptives\nggplot(mh, aes(x = IQ, y = Abil)) +\n  geom_jitter() +\n  geom_smooth(method = \"lm\")## `geom_smooth()` using formula 'y ~ x'"},{"path":"session-4-1.html","id":"correlation","chapter":"9 Session 4.1","heading":"9.4 Correlation","text":"actually lot different packages functions can use run correlations, use correlation() function correlation package. Remember help function can type e.g., ?correlation console window. correlation() function requires:name data set usingThe name first variable want select correlationThe name second variable want select correlationThe type correlation want run: e.g. pearson, spearmanThe type NHST tail want run: e.g. \"less\",\"greater\", \"two.sided\"case, want correlate IQ Abil dataset mh, going use Pearson correlation, directional hypothesis (IQ Abil positively correlated), use one-sided test increase power.","code":"\ncorrelation(data = mh, \n            select = \"IQ\", \n            select2 = \"Abil\",  \n            method = \"pearson\", \n            alternative = \"greater\")"},{"path":"session-4-1.html","id":"multiple-correlations","chapter":"9 Session 4.1","heading":"9.5 Multiple Correlations","text":"going focus relationship two variables want conduct correlations multiple variables data set easy correlation package.pairs.panels()) function comes psych library creates matrix scatterplots, histograms, correlation coefficients can use give overview relationships one time. useful checking assumptions one place.code :Takes dataset mh ;Uses select() get rid Participant column ;Pipes remaining data pairs.panels() functionThe additional arguments:\nellipses = FALSE turns correlation ellipses,\nlm = TRUE use linear line best fit,\n`method = \"pearson\", specifies Pearson correlation.\nellipses = FALSE turns correlation ellipses,lm = TRUE use linear line best fit,`method = \"pearson\", specifies Pearson correlation.additional arguments adjust plot pairs.panel creates can look help documentation interested.perform multiple correlations one go, use correlation() function rather specifying two variables correlate, can also provide data frame multiple variables run possible correlations variables. Similar , want remove Participant column .method controls correlation computed, default pearson needed run non-parametric version change spearman.p_adjust allows apply correction multiple comparisons correlation analysis.running multiple correlations may positive may negative, option specify one two-tailed test.","code":"\nmh %>%\n  select(-Participant) %>%\n  pairs.panels(ellipses = FALSE, \n               lm = TRUE, \n               method = \"pearson\")\ncorr_results <- mh %>%\n  select(-Participant) %>%\n  correlation(method = \"pearson\", \n              p_adjust = \"bonferroni\")\n\ncorr_results"},{"path":"session-4-1.html","id":"linear-regression","chapter":"9 Session 4.1","heading":"9.6 Linear regression","text":"perform linear regression simple using function lm() (linear model). First construct model, use summary() summarise results.~ tilde context probably usefully translated \"\", .e., predict Ability IQ using data mh.","code":"\nmod <- lm(formula = Abil ~ IQ, data = mh)\nsummary(mod)## \n## Call:\n## lm(formula = Abil ~ IQ, data = mh)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -11.1033  -4.4932  -0.6648   4.8215  13.1255 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 41.70975    7.08786   5.885 5.57e-08 ***\n## IQ           0.12288    0.06944   1.769   0.0799 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 5.747 on 98 degrees of freedom\n## Multiple R-squared:  0.03096,    Adjusted R-squared:  0.02107 \n## F-statistic: 3.131 on 1 and 98 DF,  p-value: 0.07993"},{"path":"session-4-1.html","id":"assumptions","chapter":"9 Session 4.1","heading":"9.7 Assumptions","text":"Finally, can also check model meets assumptions linear regression using performance package. really excellent tool contains (amongst may things), handy wrapper function check_model() performs assumption tests provides clear interpretable output:get error Error grid.Call(C_convert, x, .integer(whatfrom), .integer(whatto),  : Viewport zero dimension(s), increase size plot pane RStudio (literally drag make bigger). ","code":"\ncheck_model(mod)"},{"path":"session-4-1.html","id":"multiple-regression","chapter":"9 Session 4.1","heading":"9.8 Multiple regression","text":"want add additional predictors, can adjusting formula:","code":"\nmod2 <- lm(formula = Abil ~ IQ + Home, data = mh) # no interaction\nsummary(mod2)\n\nmod3 <- lm(formula = Abil ~ IQ * Home, data = mh) # with interaction between predictors\nsummary(mod3)## \n## Call:\n## lm(formula = Abil ~ IQ + Home, data = mh)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -9.6274 -3.2104  0.0216  2.7649 14.5198 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) 28.44312    5.72295   4.970 2.88e-06 ***\n## IQ           0.04918    0.05451   0.902    0.369    \n## Home         0.17180    0.02106   8.157 1.25e-12 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.449 on 97 degrees of freedom\n## Multiple R-squared:  0.4252, Adjusted R-squared:  0.4133 \n## F-statistic: 35.88 on 2 and 97 DF,  p-value: 2.171e-12\n## \n## \n## Call:\n## lm(formula = Abil ~ IQ * Home, data = mh)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.2126 -3.1279 -0.2797  2.5575 14.5648 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)  \n## (Intercept) 67.547054  28.274459   2.389   0.0189 *\n## IQ          -0.333183   0.276187  -1.206   0.2306  \n## Home        -0.151691   0.230066  -0.659   0.5113  \n## IQ:Home      0.003156   0.002235   1.412   0.1612  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.427 on 96 degrees of freedom\n## Multiple R-squared:  0.4369, Adjusted R-squared:  0.4193 \n## F-statistic: 24.83 on 3 and 96 DF,  p-value: 5.633e-12"},{"path":"session-4-1.html","id":"glossary-regression","chapter":"9 Session 4.1","heading":"9.9 Glossary","text":"","code":""},{"path":"session-4-1.html","id":"resources-regression","chapter":"9 Session 4.1","heading":"9.10 Further resources","text":"Learning Statistical Models Simulation RIntroduction GLMStatistical Inference via Data Science: ModernDive R Tidyverse!","code":""},{"path":"session-4-2.html","id":"session-4-2","chapter":"10 Session 4.2","heading":"10 Session 4.2","text":"","code":""},{"path":"session-4-2.html","id":"test-your-understanding-1-1","chapter":"10 Session 4.2","heading":"10.1 Test your understanding 1","text":"resulting columns four examples?budget %>% select(contains(\"_\"))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\nbudget %>% select(num_range(\"expenses_\", 2019:2020))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\nbudget %>% select(starts_with(\"sales\"))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\nbudget %>% select(ends_with(\"2020\"))\n\nsales_2019, sales_2020sales_2020, expenses_2020, satisfaction_2020sales_2019, sales_2020, expenses_2019, expenses_2020, satisfaction_2019, satisfaction_2020expenses_2019, expenses_2020\nIDs kept table ?demo %>% filter(score < 80)\n1, 2233, 4demo %>% filter(grade == \"\")\n1, 2233, 4demo %>% filter(grade != \"\")\n1, 2233, 4demo %>% filter(score == 91)\n1, 2233, 4How find maximum sales region?","code":"budget3 %>%\n  group_by(region) %>%\n  summarise(max_sales = max(region)budget3 %>%\n  group_by(region) %>%\n  summarise(max_sales = max(sales)budget3 %>%\n  group_by(sales) %>%\n  summarise(max_sales = max(sales)budget3 %>%\n  group_by(sales) %>%\n  summarise(max_sales = max(region)"},{"path":"session-4-2.html","id":"exercises-1","chapter":"10 Session 4.2","heading":"10.2 Exercises 1","text":"try exercises using simulated dataset call centre notes long caller waited call answered, long call lasted, issue calling , employee answered call, resulting customer satisfaction. really push worry look solutions hints.","code":"\n# from https://www.kaggle.com/kyanyoga/sample-sales-data\nlibrary(tidyverse)\nsurvey_data <- read_csv(\"https://psyteachr.github.io/ads-v1/data/survey_data.csv\")## Rows: 707 Columns: 7\n## -- Column specification --------------------------------------------------------\n## Delimiter: \",\"\n## chr  (3): caller_id, employee_id, issue_category\n## dbl  (3): wait_time, call_time, satisfaction\n## dttm (1): call_start\n## \n## i Use `spec()` to retrieve the full column specification for this data.\n## i Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"session-4-2.html","id":"creating-new-categories","chapter":"10 Session 4.2","heading":"10.2.1 Creating new categories","text":"Employees 1-5 trained Michael employees 6-10 trained Dwight.Create new column named trainer lists trainer employee., calculate average satisfaction scores employees trained trainer visualise satisfaction scores whatever way think best.r hide(\"Hint\")\nadd trainer column can use case_when() specify multiple criteria (e.g., employee 1-5, Michael, employee 6-10 Dwight).\nr unhide()","code":"\n# case_when() method\nsurvey_data <- survey_data %>%\n  mutate(trainer = case_when(employee_id %in% c(\"E01\", \"E02\", \"E03\", \"E04\", \"E05\") ~ \"Michael\",\n                             employee_id %in% c(\"E06\", \"E07\", \"E08\", \"E09\", \"E10\") ~ \"Dwight\"))\n\n# mean satisfaction scores\nsurvey_data %>%\n  group_by(trainer) %>%\n  summarise(mean_satisfaction = mean(satisfaction))\n\n# possible visualisation \n\nggplot(survey_data, aes(x = satisfaction, fill = trainer)) +\n  geom_histogram(binwidth = 1, show.legend = FALSE, colour = \"black\") +\n  facet_wrap(~trainer) +\n  labs(title = \"Satisfaction scores by employee trainer\")"},{"path":"session-4-2.html","id":"filter-by-calculated-score","chapter":"10 Session 4.2","heading":"10.2.2 Filter by calculated score","text":"First, calculate average wait time create dataset named long_wait just contains data customers waited average wait time.Create visualisation shows many customers waited average wait time employee.","code":"\nsurvey_data %>%\n  summarise(mean = mean(wait_time))\n\nlong_wait <- survey_data %>%\n  filter(wait_time > 187)\nlong_wait %>%\n  ggplot(aes(x = employee_id)) +\n  geom_bar()"},{"path":"session-4-2.html","id":"exercises-2","chapter":"10 Session 4.2","heading":"10.3 Exercises 2","text":"lots different use cases ****_join() functions. exercises allow practice different joins. examples joins might helpful work, please post Teams week 6 channel, many concrete examples can help distinguish different joins.","code":""},{"path":"session-4-2.html","id":"grade-data","chapter":"10 Session 4.2","heading":"10.3.1 Grade data","text":"University Glasgow's Schedule grading scheme uses 22-point alphanumeric scale (information summative report assessment information sheet). alphanumeric grade (e.g., B2) underlying numeric Grade Point (e.g., 16).Often working student grades provided us one forms, need able go two. example, need numeric form order able calculate descriptive statistics mean grade, need alphanumeric form release student records.Download grade_data.csv, grade_data2.csv scheduleA.csv data folder.Download grade_data.csv, grade_data2.csv scheduleA.csv data folder.Read scheduleA.csv save object named schedule.Read scheduleA.csv save object named schedule.Read grade_data1.csv save object named grades1.Read grade_data1.csv save object named grades1.Read grade_data2.csv save object named grades2.Read grade_data2.csv save object named grades2.","code":"\nschedule <- read_csv(\"data/scheduleA.csv\")\ngrades1 <- read_csv(\"data/grade_data1.csv\") \ngrades2 <- read_csv(\"data/grade_data2.csv\")"},{"path":"session-4-2.html","id":"matching-the-variable-types","chapter":"10 Session 4.2","heading":"10.3.2 Matching the variable types","text":"UofG, students given GUID, numeric ID number. However, ID number also combined first letter surname create username used email address. example, ID 1234567 surname Nordmann, username 1234567n. data wrangling perspective annoying numeric ID stored numeric data, username stored character letter end. grades1 numeric id whilst grades2 additional letter. order join datasets, need standardise variables.First, remove letter character id using function stringr::str_replace_all(), replaces text matches pattern. , using pattern \"[-z]\", matches lowercase letters z, replacing \"\". See help ?about_search_regex info set patterns (can get really complex).Now, transform data type id matches data type grades2.","code":"\ngrades1 <- grades1 %>%\n  mutate(id = str_replace_all(\n    id, # the variable you want to search\n    pattern = \"[a-z]\", # find all letters a-z\n    replacement = \"\" # replace with nothing\n  ))  \n# check variable types\nglimpse(grades1)\nglimpse(grades2) \n\ngrades1 <- grades1 %>%\n  mutate(id = as.numeric(id))"},{"path":"session-4-2.html","id":"complete-records","chapter":"10 Session 4.2","heading":"10.3.3 Complete records","text":"example, want join grade data schedule student grade grade grade point. also want complete record students course, students missing grades still included data.Join grades1 scheduleA store table object named exam_all.grades2 save essay_all.exam_all essay_all 100 observations 4 variables.want keep data grade_data1 grade_data2, want alphanumeric grades schedule Grade Point values exist grades. E.g., -one awarded F1, final dataset .","code":"\nexam_all <- left_join(grades1, schedule, by = \"Points\")\nessay_all <- left_join(grades2, schedule, by = \"Points\")"},{"path":"session-4-2.html","id":"missing-data","chapter":"10 Session 4.2","heading":"10.3.4 Missing data","text":"Alternatively, may wish dataset contains data students submitted assessment grade. First, run summary() exam_all essay_all.many exam grades missing? many essay grades missing? Now, create object exam_grades joins together grades1 schedule, time resulting object contain data students grade. grades2 store essay_grades., given know many data points missing data set:many observations exam_grades ? many observations essay_grades ? worth noting reality actually go back raw data another join get dataset, just remove missing response adding %>% drop_na() exam_all essay_all. However, purposes teaching joins, slightly artificial way.Now, create dataset completes joins grades students grade essay exam.exam_grades essay_grades variables Assessment, Points Grades named , different data, amend suffix resulting variables named Points_exam Points_essay etc. may need consult help documentation see example figure .Clean file select() keep variables id, Grade_exam, Grade_essayHow many students grade exam essay? Now create dataset no_essay contains students grade exam, essay.many students grade exam essay? Finally, now make dataset no_exam contains students grade essay examHow many students grade exam essay? ","code":"\nexam_grades <- inner_join(grades1, schedule, by = \"Points\")\nessay_grades <- inner_join(grades2, schedule, by = \"Points\")\ncompletes <- inner_join(exam_grades, essay_grades, \n                        by = \"id\", \n                        suffix = c(\"_exam\", \"_essay\")) %>%\n  select(id, Grade_exam, Grade_essay)\nno_essay <- anti_join(exam_grades, essay_grades, by = \"id\")\nno_exam <- anti_join(essay_grades, exam_grades, by = \"id\")"},{"path":"glossary.html","id":"glossary","chapter":"A Glossary","heading":"A Glossary","text":"can use glossary() function automatically link term psyTeachR glossary make project-specific glossary.create link glossary include tooltip short definition hover term. Use following syntax inline r: glossary(\"word\"). example, common data types integer, double, character.need link definition, using different form word, add display version second argument (display). can also override automatic short definition providing third argument (def). Add argument link = FALSE just want hover definition link psyTeachR glossary.[1] \"Data Types\"can add glossary table end chapter following code. creates table terms used chapter previous glossary_table() function. uses kableExtra(), use code chunk, set results='asis'.want contribute glossary, fork github project, add terms submit pull request, suggest new term issues page.","code":"\nglossary(\"data type\", \n         display = \"Data Types\", \n         def = \"My custom definition of data types\", \n         link = FALSE)```{r, echo=FALSE, results='asis'}\nglossary_table()```"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit (DeBruine, 2021), provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
